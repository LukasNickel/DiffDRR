{
 "cells": [
  {
   "cell_type": "raw",
   "id": "13e4e5c2",
   "metadata": {},
   "source": [
    "---\n",
    "title: utils\n",
    "description: Utility functions\n",
    "output-file: utils.html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea144574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c12d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4391cc-5fe3-422e-bf0e-2ff23cd4c11d",
   "metadata": {},
   "source": [
    "## SO(3) parameterization conversions\n",
    "\n",
    "Implementations to convert `rotation_10d` ([Peretroukhin et al., 2021](https://arxiv.org/abs/2006.01031)) and `quaternion_adjugate` ([Hanson and Hanson, 2022](https://arxiv.org/abs/2205.09116)) parameterizations of SO(3) to quaternions. These can then be turned into rotation matrices by `PyTorch3D`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e82b362-c99f-412a-8951-55cc19cbad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb29f4-fdfc-4606-bc6d-6ecb3796c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "PARAMETERIZATIONS = [\n",
    "    \"axis_angle\",\n",
    "    \"euler_angles\",\n",
    "    \"matrix\",\n",
    "    \"quaternion\",\n",
    "    \"quaternion_adjugate\",\n",
    "    \"rotation_6d\",\n",
    "    \"rotation_10d\",\n",
    "    \"so3_log_map\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819da27f-91ab-4065-b033-d0b73deae208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _10vec_to_4x4symmetric(vec):\n",
    "    \"\"\"Convert a 10-vector to a symmetric 4x4 matrix.\"\"\"\n",
    "    b = len(vec)\n",
    "    A = torch.zeros(b, 4, 4, device=vec.device)\n",
    "    idx, jdx = torch.triu_indices(4, 4)\n",
    "    A[..., idx, jdx] = vec\n",
    "    A[..., jdx, idx] = vec\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da8a8fa-3fb0-4366-b898-fccb287049ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rotation_10d_to_quaternion(rotation: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a 10-vector into a symmetric matrix, whose eigenvector corresponding\n",
    "    to the eigenvalue of minimum modulus is the resulting quaternion.\n",
    "\n",
    "    Source: https://arxiv.org/abs/2006.01031\n",
    "    \"\"\"\n",
    "    A = _10vec_to_4x4symmetric(rotation)  # A is a symmetric data matrix\n",
    "    return torch.linalg.eigh(A).eigenvectors[..., 0]\n",
    "\n",
    "\n",
    "def quaternion_to_rotation_10d(q: torch.Tensor) -> torch.Tensor:\n",
    "    A = -torch.einsum(\"bi, bj -> bij\", q, q)\n",
    "    idx, jdx = torch.triu_indices(4, 4)\n",
    "    return A[..., idx, jdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace62d9b-2ece-4b24-9085-14b73cbbb9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def quaternion_adjugate_to_quaternion(rotation: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a 10-vector in the quaternion adjugate, a symmetric matrix whose\n",
    "    eigenvector corresponding to the eigenvalue of maximum modulus is the\n",
    "    (unnormalized) quaternion. Uses a fast method to solve for the eigenvector\n",
    "    without explicity computing the eigendecomposition.\n",
    "\n",
    "    Source: https://arxiv.org/abs/2205.09116\n",
    "    \"\"\"\n",
    "    A = _10vec_to_4x4symmetric(rotation)  # A is the quaternion adjugate\n",
    "    norms = A.norm(dim=1).amax(dim=1, keepdim=True)\n",
    "    max_eigenvectors = torch.argmax(A.norm(dim=1), dim=1)\n",
    "    return A[range(len(A)), max_eigenvectors] / norms\n",
    "\n",
    "\n",
    "def quaternion_to_quaternion_adjugate(q: torch.Tensor) -> torch.Tensor:\n",
    "    A = torch.einsum(\"bi, bj -> bij\", q, q)\n",
    "    idx, jdx = torch.triu_indices(4, 4)\n",
    "    return A[..., idx, jdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3c1c77-ba8b-4221-8f45-262bfbfc659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert(\n",
    "    rotation,\n",
    "    input_parameterization,\n",
    "    output_parameterization,\n",
    "    input_convention=None,\n",
    "    output_convention=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert a rotation in SO(3) from some parameterization to another.\n",
    "    Intermediated by temporary conversion to a rotation matrix.\n",
    "\n",
    "    If input or output parameterizations are `euler_angles`, need to specify\n",
    "    `input_convention` or `output_convention`.\n",
    "\n",
    "    Note: conversions to `rotation_10d` or `quaternion_adjugate` are not unique.\n",
    "    \"\"\"\n",
    "    matrix = _convert_to_rotation_matrix(\n",
    "        rotation, input_parameterization, input_convention\n",
    "    )\n",
    "    return _convert_from_rotation_matrix(\n",
    "        matrix, output_parameterization, output_convention\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2994e1-130a-4128-a6bc-0685b5d2dd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _convert_to_rotation_matrix(rotation, parameterization, convention, **kwargs):\n",
    "    \"\"\"Convert any parameterization of a rotation to a matrix representation.\"\"\"\n",
    "    if parameterization == \"axis_angle\":\n",
    "        R = axis_angle_to_matrix(rotation)\n",
    "    elif parameterization == \"euler_angles\":\n",
    "        R = euler_angles_to_matrix(rotation, convention)\n",
    "    elif parameterization == \"matrix\":\n",
    "        R = rotation\n",
    "    elif parameterization == \"quaternion\":\n",
    "        R = quaternion_to_matrix(rotation)\n",
    "    elif parameterization == \"rotation_6d\":\n",
    "        R = rotation_6d_to_matrix(rotation)\n",
    "    elif parameterization == \"rotation_10d\":\n",
    "        R = quaternion_to_matrix(rotation_10d_to_quaternion(rotation))\n",
    "    elif parameterization == \"quaternion_adjugate\":\n",
    "        R = quaternion_to_matrix(quaternion_adjugate_to_quaternion(rotation))\n",
    "    elif parameterization == \"so3_log_map\":\n",
    "        R = so3_exp_map(rotation, **kwargs)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"parameterization must be in {PARAMETERIZATIONS}, not {parameterization}\"\n",
    "        )\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b344db2-2340-446d-a8a7-c08f67230ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _convert_from_rotation_matrix(matrix, parameterization, convention=None, **kwargs):\n",
    "    \"Convert a rotation matrix to any allowed parameterization.\"\n",
    "    if parameterization == \"axis_angle\":\n",
    "        rotation = matrix_to_axis_angle(matrix)\n",
    "    elif parameterization == \"euler_angles\":\n",
    "        rotation = matrix_to_euler_angles(matrix, convention)\n",
    "    elif parameterization == \"matrix\":\n",
    "        rotation = matrix\n",
    "    elif parameterization == \"quaternion\":\n",
    "        rotation = matrix_to_quaternion(matrix)\n",
    "    elif parameterization == \"rotation_6d\":\n",
    "        rotation = matrix_to_rotation_6d(matrix)\n",
    "    elif parameterization in [\"rotation_10d\"]:\n",
    "        q = _convert_from_rotation_matrix(matrix, \"quaternion\")\n",
    "        rotation = quaternion_to_rotation_10d(q)\n",
    "    elif parameterization == \"quaternion_adjugate\":\n",
    "        q = _convert_from_rotation_matrix(matrix, \"quaternion\")\n",
    "        rotation = quaternion_to_quaternion_adjugate(q)\n",
    "    elif parameterization == \"so3_log_map\":\n",
    "        rotation = so3_log_map(matrix, **kwargs)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"parameterization must be in {PARAMETERIZATIONS}, not {parameterization}\"\n",
    "        )\n",
    "    return rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1a7ebf-8103-4f63-97b4-c40bf72a7d33",
   "metadata": {},
   "source": [
    "### `PyTorch3D` conversions port\n",
    "\n",
    "`PyTorch3D` has many useful conversion functions for transforming between multiple parameterizations of $\\mathbf{SO}(3)$ and $\\mathbf{SE}(3)$. However, installing `PyTorch3D` can be annoying for users not on Linux. We include the [required conversion functions for `PyTorch3D`](https://github.com/facebookresearch/pytorch3d/tree/main/pytorch3d/transforms) below. The original [LICENSE](https://github.com/facebookresearch/pytorch3d/blob/main/LICENSE) from `PyTorch3D` is also included:\n",
    "\n",
    "```\n",
    "BSD License\n",
    "\n",
    "For PyTorch3D software\n",
    "\n",
    "Copyright (c) Meta Platforms, Inc. and affiliates. All rights reserved.\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without modification,\n",
    "are permitted provided that the following conditions are met:\n",
    "\n",
    " * Redistributions of source code must retain the above copyright notice, this\n",
    "   list of conditions and the following disclaimer.\n",
    "\n",
    " * Redistributions in binary form must reproduce the above copyright notice,\n",
    "   this list of conditions and the following disclaimer in the documentation\n",
    "   and/or other materials provided with the distribution.\n",
    "\n",
    " * Neither the name Meta nor the names of its contributors may be used to\n",
    "   endorse or promote products derived from this software without specific\n",
    "   prior written permission.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n",
    "ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n",
    "WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\n",
    "ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n",
    "(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n",
    "LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\n",
    "ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n",
    "(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n",
    "SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e084512-4441-4bc5-b1f1-ab38aa5b27aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "# pytorch3d/transforms/rotation_conversions.py\n",
    "\n",
    "from typing import Optional, Union\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "Device = Union[str, torch.device]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The transformation matrices returned from the functions in this file assume\n",
    "the points on which the transformation will be applied are column vectors.\n",
    "i.e. the R matrix is structured as\n",
    "\n",
    "    R = [\n",
    "            [Rxx, Rxy, Rxz],\n",
    "            [Ryx, Ryy, Ryz],\n",
    "            [Rzx, Rzy, Rzz],\n",
    "        ]  # (3, 3)\n",
    "\n",
    "This matrix can be applied to column vectors by post multiplication\n",
    "by the points e.g.\n",
    "\n",
    "    points = [[0], [1], [2]]  # (3 x 1) xyz coordinates of a point\n",
    "    transformed_points = R * points\n",
    "\n",
    "To apply the same matrix to points which are row vectors, the R matrix\n",
    "can be transposed and pre multiplied by the points:\n",
    "\n",
    "e.g.\n",
    "    points = [[0, 1, 2]]  # (1 x 3) xyz coordinates of a point\n",
    "    transformed_points = points * R.transpose(1, 0)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def quaternion_to_matrix(quaternions: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert rotations given as quaternions to rotation matrices.\n",
    "\n",
    "    Args:\n",
    "        quaternions: quaternions with real part first,\n",
    "            as tensor of shape (..., 4).\n",
    "\n",
    "    Returns:\n",
    "        Rotation matrices as tensor of shape (..., 3, 3).\n",
    "    \"\"\"\n",
    "    r, i, j, k = torch.unbind(quaternions, -1)\n",
    "    # pyre-fixme[58]: `/` is not supported for operand types `float` and `Tensor`.\n",
    "    two_s = 2.0 / (quaternions * quaternions).sum(-1)\n",
    "\n",
    "    o = torch.stack(\n",
    "        (\n",
    "            1 - two_s * (j * j + k * k),\n",
    "            two_s * (i * j - k * r),\n",
    "            two_s * (i * k + j * r),\n",
    "            two_s * (i * j + k * r),\n",
    "            1 - two_s * (i * i + k * k),\n",
    "            two_s * (j * k - i * r),\n",
    "            two_s * (i * k - j * r),\n",
    "            two_s * (j * k + i * r),\n",
    "            1 - two_s * (i * i + j * j),\n",
    "        ),\n",
    "        -1,\n",
    "    )\n",
    "    return o.reshape(quaternions.shape[:-1] + (3, 3))\n",
    "\n",
    "\n",
    "def _copysign(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Return a tensor where each element has the absolute value taken from the,\n",
    "    corresponding element of a, with sign taken from the corresponding\n",
    "    element of b. This is like the standard copysign floating-point operation,\n",
    "    but is not careful about negative 0 and NaN.\n",
    "\n",
    "    Args:\n",
    "        a: source tensor.\n",
    "        b: tensor whose signs will be used, of the same shape as a.\n",
    "\n",
    "    Returns:\n",
    "        Tensor of the same shape as a with the signs of b.\n",
    "    \"\"\"\n",
    "    signs_differ = (a < 0) != (b < 0)\n",
    "    return torch.where(signs_differ, -a, a)\n",
    "\n",
    "\n",
    "def _sqrt_positive_part(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Returns torch.sqrt(torch.max(0, x))\n",
    "    but with a zero subgradient where x is 0.\n",
    "    \"\"\"\n",
    "    ret = torch.zeros_like(x)\n",
    "    positive_mask = x > 0\n",
    "    ret[positive_mask] = torch.sqrt(x[positive_mask])\n",
    "    return ret\n",
    "\n",
    "\n",
    "def matrix_to_quaternion(matrix: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert rotations given as rotation matrices to quaternions.\n",
    "\n",
    "    Args:\n",
    "        matrix: Rotation matrices as tensor of shape (..., 3, 3).\n",
    "\n",
    "    Returns:\n",
    "        quaternions with real part first, as tensor of shape (..., 4).\n",
    "    \"\"\"\n",
    "    if matrix.size(-1) != 3 or matrix.size(-2) != 3:\n",
    "        raise ValueError(f\"Invalid rotation matrix shape {matrix.shape}.\")\n",
    "\n",
    "    batch_dim = matrix.shape[:-2]\n",
    "    m00, m01, m02, m10, m11, m12, m20, m21, m22 = torch.unbind(\n",
    "        matrix.reshape(batch_dim + (9,)), dim=-1\n",
    "    )\n",
    "\n",
    "    q_abs = _sqrt_positive_part(\n",
    "        torch.stack(\n",
    "            [\n",
    "                1.0 + m00 + m11 + m22,\n",
    "                1.0 + m00 - m11 - m22,\n",
    "                1.0 - m00 + m11 - m22,\n",
    "                1.0 - m00 - m11 + m22,\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # we produce the desired quaternion multiplied by each of r, i, j, k\n",
    "    quat_by_rijk = torch.stack(\n",
    "        [\n",
    "            # pyre-fixme[58]: `**` is not supported for operand types `Tensor` and\n",
    "            #  `int`.\n",
    "            torch.stack([q_abs[..., 0] ** 2, m21 - m12, m02 - m20, m10 - m01], dim=-1),\n",
    "            # pyre-fixme[58]: `**` is not supported for operand types `Tensor` and\n",
    "            #  `int`.\n",
    "            torch.stack([m21 - m12, q_abs[..., 1] ** 2, m10 + m01, m02 + m20], dim=-1),\n",
    "            # pyre-fixme[58]: `**` is not supported for operand types `Tensor` and\n",
    "            #  `int`.\n",
    "            torch.stack([m02 - m20, m10 + m01, q_abs[..., 2] ** 2, m12 + m21], dim=-1),\n",
    "            # pyre-fixme[58]: `**` is not supported for operand types `Tensor` and\n",
    "            #  `int`.\n",
    "            torch.stack([m10 - m01, m20 + m02, m21 + m12, q_abs[..., 3] ** 2], dim=-1),\n",
    "        ],\n",
    "        dim=-2,\n",
    "    )\n",
    "\n",
    "    # We floor here at 0.1 but the exact level is not important; if q_abs is small,\n",
    "    # the candidate won't be picked.\n",
    "    flr = torch.tensor(0.1).to(dtype=q_abs.dtype, device=q_abs.device)\n",
    "    quat_candidates = quat_by_rijk / (2.0 * q_abs[..., None].max(flr))\n",
    "\n",
    "    # if not for numerical problems, quat_candidates[i] should be same (up to a sign),\n",
    "    # forall i; we pick the best-conditioned one (with the largest denominator)\n",
    "    out = quat_candidates[\n",
    "        F.one_hot(q_abs.argmax(dim=-1), num_classes=4) > 0.5, :\n",
    "    ].reshape(batch_dim + (4,))\n",
    "    return standardize_quaternion(out)\n",
    "\n",
    "\n",
    "def _axis_angle_rotation(axis: str, angle: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Return the rotation matrices for one of the rotations about an axis\n",
    "    of which Euler angles describe, for each value of the angle given.\n",
    "\n",
    "    Args:\n",
    "        axis: Axis label \"X\" or \"Y or \"Z\".\n",
    "        angle: any shape tensor of Euler angles in radians\n",
    "\n",
    "    Returns:\n",
    "        Rotation matrices as tensor of shape (..., 3, 3).\n",
    "    \"\"\"\n",
    "\n",
    "    cos = torch.cos(angle)\n",
    "    sin = torch.sin(angle)\n",
    "    one = torch.ones_like(angle)\n",
    "    zero = torch.zeros_like(angle)\n",
    "\n",
    "    if axis == \"X\":\n",
    "        R_flat = (one, zero, zero, zero, cos, -sin, zero, sin, cos)\n",
    "    elif axis == \"Y\":\n",
    "        R_flat = (cos, zero, sin, zero, one, zero, -sin, zero, cos)\n",
    "    elif axis == \"Z\":\n",
    "        R_flat = (cos, -sin, zero, sin, cos, zero, zero, zero, one)\n",
    "    else:\n",
    "        raise ValueError(\"letter must be either X, Y or Z.\")\n",
    "\n",
    "    return torch.stack(R_flat, -1).reshape(angle.shape + (3, 3))\n",
    "\n",
    "\n",
    "def euler_angles_to_matrix(euler_angles: torch.Tensor, convention: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert rotations given as Euler angles in radians to rotation matrices.\n",
    "\n",
    "    Args:\n",
    "        euler_angles: Euler angles in radians as tensor of shape (..., 3).\n",
    "        convention: Convention string of three uppercase letters from\n",
    "            {\"X\", \"Y\", and \"Z\"}.\n",
    "\n",
    "    Returns:\n",
    "        Rotation matrices as tensor of shape (..., 3, 3).\n",
    "    \"\"\"\n",
    "    if euler_angles.dim() == 0 or euler_angles.shape[-1] != 3:\n",
    "        raise ValueError(\"Invalid input euler angles.\")\n",
    "    if len(convention) != 3:\n",
    "        raise ValueError(\"Convention must have 3 letters.\")\n",
    "    if convention[1] in (convention[0], convention[2]):\n",
    "        raise ValueError(f\"Invalid convention {convention}.\")\n",
    "    for letter in convention:\n",
    "        if letter not in (\"X\", \"Y\", \"Z\"):\n",
    "            raise ValueError(f\"Invalid letter {letter} in convention string.\")\n",
    "    matrices = [\n",
    "        _axis_angle_rotation(c, e)\n",
    "        for c, e in zip(convention, torch.unbind(euler_angles, -1))\n",
    "    ]\n",
    "    # return functools.reduce(torch.matmul, matrices)\n",
    "    return torch.matmul(torch.matmul(matrices[0], matrices[1]), matrices[2])\n",
    "\n",
    "\n",
    "def _angle_from_tan(\n",
    "    axis: str, other_axis: str, data, horizontal: bool, tait_bryan: bool\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Extract the first or third Euler angle from the two members of\n",
    "    the matrix which are positive constant times its sine and cosine.\n",
    "\n",
    "    Args:\n",
    "        axis: Axis label \"X\" or \"Y or \"Z\" for the angle we are finding.\n",
    "        other_axis: Axis label \"X\" or \"Y or \"Z\" for the middle axis in the\n",
    "            convention.\n",
    "        data: Rotation matrices as tensor of shape (..., 3, 3).\n",
    "        horizontal: Whether we are looking for the angle for the third axis,\n",
    "            which means the relevant entries are in the same row of the\n",
    "            rotation matrix. If not, they are in the same column.\n",
    "        tait_bryan: Whether the first and third axes in the convention differ.\n",
    "\n",
    "    Returns:\n",
    "        Euler Angles in radians for each matrix in data as a tensor\n",
    "        of shape (...).\n",
    "    \"\"\"\n",
    "\n",
    "    i1, i2 = {\"X\": (2, 1), \"Y\": (0, 2), \"Z\": (1, 0)}[axis]\n",
    "    if horizontal:\n",
    "        i2, i1 = i1, i2\n",
    "    even = (axis + other_axis) in [\"XY\", \"YZ\", \"ZX\"]\n",
    "    if horizontal == even:\n",
    "        return torch.atan2(data[..., i1], data[..., i2])\n",
    "    if tait_bryan:\n",
    "        return torch.atan2(-data[..., i2], data[..., i1])\n",
    "    return torch.atan2(data[..., i2], -data[..., i1])\n",
    "\n",
    "\n",
    "def _index_from_letter(letter: str) -> int:\n",
    "    if letter == \"X\":\n",
    "        return 0\n",
    "    if letter == \"Y\":\n",
    "        return 1\n",
    "    if letter == \"Z\":\n",
    "        return 2\n",
    "    raise ValueError(\"letter must be either X, Y or Z.\")\n",
    "\n",
    "\n",
    "def matrix_to_euler_angles(matrix: torch.Tensor, convention: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert rotations given as rotation matrices to Euler angles in radians.\n",
    "\n",
    "    Args:\n",
    "        matrix: Rotation matrices as tensor of shape (..., 3, 3).\n",
    "        convention: Convention string of three uppercase letters.\n",
    "\n",
    "    Returns:\n",
    "        Euler angles in radians as tensor of shape (..., 3).\n",
    "    \"\"\"\n",
    "    if len(convention) != 3:\n",
    "        raise ValueError(\"Convention must have 3 letters.\")\n",
    "    if convention[1] in (convention[0], convention[2]):\n",
    "        raise ValueError(f\"Invalid convention {convention}.\")\n",
    "    for letter in convention:\n",
    "        if letter not in (\"X\", \"Y\", \"Z\"):\n",
    "            raise ValueError(f\"Invalid letter {letter} in convention string.\")\n",
    "    if matrix.size(-1) != 3 or matrix.size(-2) != 3:\n",
    "        raise ValueError(f\"Invalid rotation matrix shape {matrix.shape}.\")\n",
    "    i0 = _index_from_letter(convention[0])\n",
    "    i2 = _index_from_letter(convention[2])\n",
    "    tait_bryan = i0 != i2\n",
    "    if tait_bryan:\n",
    "        central_angle = torch.asin(\n",
    "            matrix[..., i0, i2] * (-1.0 if i0 - i2 in [-1, 2] else 1.0)\n",
    "        )\n",
    "    else:\n",
    "        central_angle = torch.acos(matrix[..., i0, i0])\n",
    "\n",
    "    o = (\n",
    "        _angle_from_tan(\n",
    "            convention[0], convention[1], matrix[..., i2], False, tait_bryan\n",
    "        ),\n",
    "        central_angle,\n",
    "        _angle_from_tan(\n",
    "            convention[2], convention[1], matrix[..., i0, :], True, tait_bryan\n",
    "        ),\n",
    "    )\n",
    "    return torch.stack(o, -1)\n",
    "\n",
    "\n",
    "def random_quaternions(\n",
    "    n: int, dtype: Optional[torch.dtype] = None, device: Optional[Device] = None\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate random quaternions representing rotations,\n",
    "    i.e. versors with nonnegative real part.\n",
    "\n",
    "    Args:\n",
    "        n: Number of quaternions in a batch to return.\n",
    "        dtype: Type to return.\n",
    "        device: Desired device of returned tensor. Default:\n",
    "            uses the current device for the default tensor type.\n",
    "\n",
    "    Returns:\n",
    "        Quaternions as tensor of shape (N, 4).\n",
    "    \"\"\"\n",
    "    if isinstance(device, str):\n",
    "        device = torch.device(device)\n",
    "    o = torch.randn((n, 4), dtype=dtype, device=device)\n",
    "    s = (o * o).sum(1)\n",
    "    o = o / _copysign(torch.sqrt(s), o[:, 0])[:, None]\n",
    "    return o\n",
    "\n",
    "\n",
    "def random_rotations(\n",
    "    n: int, dtype: Optional[torch.dtype] = None, device: Optional[Device] = None\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate random rotations as 3x3 rotation matrices.\n",
    "\n",
    "    Args:\n",
    "        n: Number of rotation matrices in a batch to return.\n",
    "        dtype: Type to return.\n",
    "        device: Device of returned tensor. Default: if None,\n",
    "            uses the current device for the default tensor type.\n",
    "\n",
    "    Returns:\n",
    "        Rotation matrices as tensor of shape (n, 3, 3).\n",
    "    \"\"\"\n",
    "    quaternions = random_quaternions(n, dtype=dtype, device=device)\n",
    "    return quaternion_to_matrix(quaternions)\n",
    "\n",
    "\n",
    "def random_rotation(\n",
    "    dtype: Optional[torch.dtype] = None, device: Optional[Device] = None\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate a single random 3x3 rotation matrix.\n",
    "\n",
    "    Args:\n",
    "        dtype: Type to return\n",
    "        device: Device of returned tensor. Default: if None,\n",
    "            uses the current device for the default tensor type\n",
    "\n",
    "    Returns:\n",
    "        Rotation matrix as tensor of shape (3, 3).\n",
    "    \"\"\"\n",
    "    return random_rotations(1, dtype, device)[0]\n",
    "\n",
    "\n",
    "def standardize_quaternion(quaternions: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a unit quaternion to a standard form: one in which the real\n",
    "    part is non negative.\n",
    "\n",
    "    Args:\n",
    "        quaternions: Quaternions with real part first,\n",
    "            as tensor of shape (..., 4).\n",
    "\n",
    "    Returns:\n",
    "        Standardized quaternions as tensor of shape (..., 4).\n",
    "    \"\"\"\n",
    "    return torch.where(quaternions[..., 0:1] < 0, -quaternions, quaternions)\n",
    "\n",
    "\n",
    "def quaternion_raw_multiply(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Multiply two quaternions.\n",
    "    Usual torch rules for broadcasting apply.\n",
    "\n",
    "    Args:\n",
    "        a: Quaternions as tensor of shape (..., 4), real part first.\n",
    "        b: Quaternions as tensor of shape (..., 4), real part first.\n",
    "\n",
    "    Returns:\n",
    "        The product of a and b, a tensor of quaternions shape (..., 4).\n",
    "    \"\"\"\n",
    "    aw, ax, ay, az = torch.unbind(a, -1)\n",
    "    bw, bx, by, bz = torch.unbind(b, -1)\n",
    "    ow = aw * bw - ax * bx - ay * by - az * bz\n",
    "    ox = aw * bx + ax * bw + ay * bz - az * by\n",
    "    oy = aw * by - ax * bz + ay * bw + az * bx\n",
    "    oz = aw * bz + ax * by - ay * bx + az * bw\n",
    "    return torch.stack((ow, ox, oy, oz), -1)\n",
    "\n",
    "\n",
    "def quaternion_multiply(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Multiply two quaternions representing rotations, returning the quaternion\n",
    "    representing their composition, i.e. the versor with nonnegative real part.\n",
    "    Usual torch rules for broadcasting apply.\n",
    "\n",
    "    Args:\n",
    "        a: Quaternions as tensor of shape (..., 4), real part first.\n",
    "        b: Quaternions as tensor of shape (..., 4), real part first.\n",
    "\n",
    "    Returns:\n",
    "        The product of a and b, a tensor of quaternions of shape (..., 4).\n",
    "    \"\"\"\n",
    "    ab = quaternion_raw_multiply(a, b)\n",
    "    return standardize_quaternion(ab)\n",
    "\n",
    "\n",
    "def quaternion_invert(quaternion: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Given a quaternion representing rotation, get the quaternion representing\n",
    "    its inverse.\n",
    "\n",
    "    Args:\n",
    "        quaternion: Quaternions as tensor of shape (..., 4), with real part\n",
    "            first, which must be versors (unit quaternions).\n",
    "\n",
    "    Returns:\n",
    "        The inverse, a tensor of quaternions of shape (..., 4).\n",
    "    \"\"\"\n",
    "\n",
    "    scaling = torch.tensor([1, -1, -1, -1], device=quaternion.device)\n",
    "    return quaternion * scaling\n",
    "\n",
    "\n",
    "def quaternion_apply(quaternion: torch.Tensor, point: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Apply the rotation given by a quaternion to a 3D point.\n",
    "    Usual torch rules for broadcasting apply.\n",
    "\n",
    "    Args:\n",
    "        quaternion: Tensor of quaternions, real part first, of shape (..., 4).\n",
    "        point: Tensor of 3D points of shape (..., 3).\n",
    "\n",
    "    Returns:\n",
    "        Tensor of rotated points of shape (..., 3).\n",
    "    \"\"\"\n",
    "    if point.size(-1) != 3:\n",
    "        raise ValueError(f\"Points are not in 3D, {point.shape}.\")\n",
    "    real_parts = point.new_zeros(point.shape[:-1] + (1,))\n",
    "    point_as_quaternion = torch.cat((real_parts, point), -1)\n",
    "    out = quaternion_raw_multiply(\n",
    "        quaternion_raw_multiply(quaternion, point_as_quaternion),\n",
    "        quaternion_invert(quaternion),\n",
    "    )\n",
    "    return out[..., 1:]\n",
    "\n",
    "\n",
    "def axis_angle_to_matrix(axis_angle: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert rotations given as axis/angle to rotation matrices.\n",
    "\n",
    "    Args:\n",
    "        axis_angle: Rotations given as a vector in axis angle form,\n",
    "            as a tensor of shape (..., 3), where the magnitude is\n",
    "            the angle turned anticlockwise in radians around the\n",
    "            vector's direction.\n",
    "\n",
    "    Returns:\n",
    "        Rotation matrices as tensor of shape (..., 3, 3).\n",
    "    \"\"\"\n",
    "    return quaternion_to_matrix(axis_angle_to_quaternion(axis_angle))\n",
    "\n",
    "\n",
    "def matrix_to_axis_angle(matrix: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert rotations given as rotation matrices to axis/angle.\n",
    "\n",
    "    Args:\n",
    "        matrix: Rotation matrices as tensor of shape (..., 3, 3).\n",
    "\n",
    "    Returns:\n",
    "        Rotations given as a vector in axis angle form, as a tensor\n",
    "            of shape (..., 3), where the magnitude is the angle\n",
    "            turned anticlockwise in radians around the vector's\n",
    "            direction.\n",
    "    \"\"\"\n",
    "    return quaternion_to_axis_angle(matrix_to_quaternion(matrix))\n",
    "\n",
    "\n",
    "def axis_angle_to_quaternion(axis_angle: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert rotations given as axis/angle to quaternions.\n",
    "\n",
    "    Args:\n",
    "        axis_angle: Rotations given as a vector in axis angle form,\n",
    "            as a tensor of shape (..., 3), where the magnitude is\n",
    "            the angle turned anticlockwise in radians around the\n",
    "            vector's direction.\n",
    "\n",
    "    Returns:\n",
    "        quaternions with real part first, as tensor of shape (..., 4).\n",
    "    \"\"\"\n",
    "    angles = torch.norm(axis_angle, p=2, dim=-1, keepdim=True)\n",
    "    half_angles = angles * 0.5\n",
    "    eps = 1e-6\n",
    "    small_angles = angles.abs() < eps\n",
    "    sin_half_angles_over_angles = torch.empty_like(angles)\n",
    "    sin_half_angles_over_angles[~small_angles] = (\n",
    "        torch.sin(half_angles[~small_angles]) / angles[~small_angles]\n",
    "    )\n",
    "    # for x small, sin(x/2) is about x/2 - (x/2)^3/6\n",
    "    # so sin(x/2)/x is about 1/2 - (x*x)/48\n",
    "    sin_half_angles_over_angles[small_angles] = (\n",
    "        0.5 - (angles[small_angles] * angles[small_angles]) / 48\n",
    "    )\n",
    "    quaternions = torch.cat(\n",
    "        [torch.cos(half_angles), axis_angle * sin_half_angles_over_angles], dim=-1\n",
    "    )\n",
    "    return quaternions\n",
    "\n",
    "\n",
    "def quaternion_to_axis_angle(quaternions: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert rotations given as quaternions to axis/angle.\n",
    "\n",
    "    Args:\n",
    "        quaternions: quaternions with real part first,\n",
    "            as tensor of shape (..., 4).\n",
    "\n",
    "    Returns:\n",
    "        Rotations given as a vector in axis angle form, as a tensor\n",
    "            of shape (..., 3), where the magnitude is the angle\n",
    "            turned anticlockwise in radians around the vector's\n",
    "            direction.\n",
    "    \"\"\"\n",
    "    norms = torch.norm(quaternions[..., 1:], p=2, dim=-1, keepdim=True)\n",
    "    half_angles = torch.atan2(norms, quaternions[..., :1])\n",
    "    angles = 2 * half_angles\n",
    "    eps = 1e-6\n",
    "    small_angles = angles.abs() < eps\n",
    "    sin_half_angles_over_angles = torch.empty_like(angles)\n",
    "    sin_half_angles_over_angles[~small_angles] = (\n",
    "        torch.sin(half_angles[~small_angles]) / angles[~small_angles]\n",
    "    )\n",
    "    # for x small, sin(x/2) is about x/2 - (x/2)^3/6\n",
    "    # so sin(x/2)/x is about 1/2 - (x*x)/48\n",
    "    sin_half_angles_over_angles[small_angles] = (\n",
    "        0.5 - (angles[small_angles] * angles[small_angles]) / 48\n",
    "    )\n",
    "    return quaternions[..., 1:] / sin_half_angles_over_angles\n",
    "\n",
    "\n",
    "def rotation_6d_to_matrix(d6: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Converts 6D rotation representation by Zhou et al. [1] to rotation matrix\n",
    "    using Gram--Schmidt orthogonalization per Section B of [1].\n",
    "    Args:\n",
    "        d6: 6D rotation representation, of size (*, 6)\n",
    "\n",
    "    Returns:\n",
    "        batch of rotation matrices of size (*, 3, 3)\n",
    "\n",
    "    [1] Zhou, Y., Barnes, C., Lu, J., Yang, J., & Li, H.\n",
    "    On the Continuity of Rotation Representations in Neural Networks.\n",
    "    IEEE Conference on Computer Vision and Pattern Recognition, 2019.\n",
    "    Retrieved from http://arxiv.org/abs/1812.07035\n",
    "    \"\"\"\n",
    "\n",
    "    a1, a2 = d6[..., :3], d6[..., 3:]\n",
    "    b1 = F.normalize(a1, dim=-1)\n",
    "    b2 = a2 - (b1 * a2).sum(-1, keepdim=True) * b1\n",
    "    b2 = F.normalize(b2, dim=-1)\n",
    "    b3 = torch.cross(b1, b2, dim=-1)\n",
    "    return torch.stack((b1, b2, b3), dim=-2)\n",
    "\n",
    "\n",
    "def matrix_to_rotation_6d(matrix: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Converts rotation matrices to 6D rotation representation by Zhou et al. [1]\n",
    "    by dropping the last row. Note that 6D representation is not unique.\n",
    "    Args:\n",
    "        matrix: batch of rotation matrices of size (*, 3, 3)\n",
    "\n",
    "    Returns:\n",
    "        6D rotation representation, of size (*, 6)\n",
    "\n",
    "    [1] Zhou, Y., Barnes, C., Lu, J., Yang, J., & Li, H.\n",
    "    On the Continuity of Rotation Representations in Neural Networks.\n",
    "    IEEE Conference on Computer Vision and Pattern Recognition, 2019.\n",
    "    Retrieved from http://arxiv.org/abs/1812.07035\n",
    "    \"\"\"\n",
    "    batch_dim = matrix.size()[:-2]\n",
    "    return matrix[..., :2, :].clone().reshape(batch_dim + (6,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66641a74-655f-495d-9868-9ec27d570018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "# pytorch3d/transforms/math.py\n",
    "from typing import Tuple\n",
    "\n",
    "DEFAULT_ACOS_BOUND: float = 1.0 - 1e-4\n",
    "\n",
    "\n",
    "def acos_linear_extrapolation(\n",
    "    x: torch.Tensor,\n",
    "    bounds: Tuple[float, float] = (-DEFAULT_ACOS_BOUND, DEFAULT_ACOS_BOUND),\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Implements `arccos(x)` which is linearly extrapolated outside `x`'s original\n",
    "    domain of `(-1, 1)`. This allows for stable backpropagation in case `x`\n",
    "    is not guaranteed to be strictly within `(-1, 1)`.\n",
    "\n",
    "    More specifically::\n",
    "\n",
    "        bounds=(lower_bound, upper_bound)\n",
    "        if lower_bound <= x <= upper_bound:\n",
    "            acos_linear_extrapolation(x) = acos(x)\n",
    "        elif x <= lower_bound: # 1st order Taylor approximation\n",
    "            acos_linear_extrapolation(x)\n",
    "                = acos(lower_bound) + dacos/dx(lower_bound) * (x - lower_bound)\n",
    "        else:  # x >= upper_bound\n",
    "            acos_linear_extrapolation(x)\n",
    "                = acos(upper_bound) + dacos/dx(upper_bound) * (x - upper_bound)\n",
    "\n",
    "    Args:\n",
    "        x: Input `Tensor`.\n",
    "        bounds: A float 2-tuple defining the region for the\n",
    "            linear extrapolation of `acos`.\n",
    "            The first/second element of `bound`\n",
    "            describes the lower/upper bound that defines the lower/upper\n",
    "            extrapolation region, i.e. the region where\n",
    "            `x <= bound[0]`/`bound[1] <= x`.\n",
    "            Note that all elements of `bound` have to be within (-1, 1).\n",
    "    Returns:\n",
    "        acos_linear_extrapolation: `Tensor` containing the extrapolated `arccos(x)`.\n",
    "    \"\"\"\n",
    "\n",
    "    lower_bound, upper_bound = bounds\n",
    "\n",
    "    if lower_bound > upper_bound:\n",
    "        raise ValueError(\"lower bound has to be smaller or equal to upper bound.\")\n",
    "\n",
    "    if lower_bound <= -1.0 or upper_bound >= 1.0:\n",
    "        raise ValueError(\"Both lower bound and upper bound have to be within (-1, 1).\")\n",
    "\n",
    "    # init an empty tensor and define the domain sets\n",
    "    acos_extrap = torch.empty_like(x)\n",
    "    x_upper = x >= upper_bound\n",
    "    x_lower = x <= lower_bound\n",
    "    x_mid = (~x_upper) & (~x_lower)\n",
    "\n",
    "    # acos calculation for upper_bound < x < lower_bound\n",
    "    acos_extrap[x_mid] = torch.acos(x[x_mid])\n",
    "    # the linear extrapolation for x >= upper_bound\n",
    "    acos_extrap[x_upper] = _acos_linear_approximation(x[x_upper], upper_bound)\n",
    "    # the linear extrapolation for x <= lower_bound\n",
    "    acos_extrap[x_lower] = _acos_linear_approximation(x[x_lower], lower_bound)\n",
    "\n",
    "    return acos_extrap\n",
    "\n",
    "\n",
    "def _acos_linear_approximation(x: torch.Tensor, x0: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculates the 1st order Taylor expansion of `arccos(x)` around `x0`.\n",
    "    \"\"\"\n",
    "    return (x - x0) * _dacos_dx(x0) + math.acos(x0)\n",
    "\n",
    "\n",
    "def _dacos_dx(x: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the derivative of `arccos(x)` w.r.t. `x`.\n",
    "    \"\"\"\n",
    "    return (-1.0) / math.sqrt(1.0 - x * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d8af87-1c30-435a-a54c-1fd8932f1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "# pytorch3d/transforms/so3.py\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "def so3_relative_angle(\n",
    "    R1: torch.Tensor,\n",
    "    R2: torch.Tensor,\n",
    "    cos_angle: bool = False,\n",
    "    cos_bound: float = 1e-4,\n",
    "    eps: float = 1e-4,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculates the relative angle (in radians) between pairs of\n",
    "    rotation matrices `R1` and `R2` with `angle = acos(0.5 * (Trace(R1 R2^T)-1))`\n",
    "\n",
    "    .. note::\n",
    "        This corresponds to a geodesic distance on the 3D manifold of rotation\n",
    "        matrices.\n",
    "\n",
    "    Args:\n",
    "        R1: Batch of rotation matrices of shape `(minibatch, 3, 3)`.\n",
    "        R2: Batch of rotation matrices of shape `(minibatch, 3, 3)`.\n",
    "        cos_angle: If==True return cosine of the relative angle rather than\n",
    "            the angle itself. This can avoid the unstable calculation of `acos`.\n",
    "        cos_bound: Clamps the cosine of the relative rotation angle to\n",
    "            [-1 + cos_bound, 1 - cos_bound] to avoid non-finite outputs/gradients\n",
    "            of the `acos` call. Note that the non-finite outputs/gradients\n",
    "            are returned when the angle is requested (i.e. `cos_angle==False`)\n",
    "            and the rotation angle is close to 0 or π.\n",
    "        eps: Tolerance for the valid trace check of the relative rotation matrix\n",
    "            in `so3_rotation_angle`.\n",
    "    Returns:\n",
    "        Corresponding rotation angles of shape `(minibatch,)`.\n",
    "        If `cos_angle==True`, returns the cosine of the angles.\n",
    "\n",
    "    Raises:\n",
    "        ValueError if `R1` or `R2` is of incorrect shape.\n",
    "        ValueError if `R1` or `R2` has an unexpected trace.\n",
    "    \"\"\"\n",
    "    R12 = torch.bmm(R1, R2.permute(0, 2, 1))\n",
    "    return so3_rotation_angle(R12, cos_angle=cos_angle, cos_bound=cos_bound, eps=eps)\n",
    "\n",
    "\n",
    "def so3_rotation_angle(\n",
    "    R: torch.Tensor,\n",
    "    eps: float = 1e-4,\n",
    "    cos_angle: bool = False,\n",
    "    cos_bound: float = 1e-4,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculates angles (in radians) of a batch of rotation matrices `R` with\n",
    "    `angle = acos(0.5 * (Trace(R)-1))`. The trace of the\n",
    "    input matrices is checked to be in the valid range `[-1-eps,3+eps]`.\n",
    "    The `eps` argument is a small constant that allows for small errors\n",
    "    caused by limited machine precision.\n",
    "\n",
    "    Args:\n",
    "        R: Batch of rotation matrices of shape `(minibatch, 3, 3)`.\n",
    "        eps: Tolerance for the valid trace check.\n",
    "        cos_angle: If==True return cosine of the rotation angles rather than\n",
    "            the angle itself. This can avoid the unstable\n",
    "            calculation of `acos`.\n",
    "        cos_bound: Clamps the cosine of the rotation angle to\n",
    "            [-1 + cos_bound, 1 - cos_bound] to avoid non-finite outputs/gradients\n",
    "            of the `acos` call. Note that the non-finite outputs/gradients\n",
    "            are returned when the angle is requested (i.e. `cos_angle==False`)\n",
    "            and the rotation angle is close to 0 or π.\n",
    "\n",
    "    Returns:\n",
    "        Corresponding rotation angles of shape `(minibatch,)`.\n",
    "        If `cos_angle==True`, returns the cosine of the angles.\n",
    "\n",
    "    Raises:\n",
    "        ValueError if `R` is of incorrect shape.\n",
    "        ValueError if `R` has an unexpected trace.\n",
    "    \"\"\"\n",
    "\n",
    "    N, dim1, dim2 = R.shape\n",
    "    if dim1 != 3 or dim2 != 3:\n",
    "        raise ValueError(\"Input has to be a batch of 3x3 Tensors.\")\n",
    "\n",
    "    rot_trace = R[:, 0, 0] + R[:, 1, 1] + R[:, 2, 2]\n",
    "\n",
    "    if ((rot_trace < -1.0 - eps) + (rot_trace > 3.0 + eps)).any():\n",
    "        raise ValueError(\"A matrix has trace outside valid range [-1-eps,3+eps].\")\n",
    "\n",
    "    # phi ... rotation angle\n",
    "    phi_cos = (rot_trace - 1.0) * 0.5\n",
    "\n",
    "    if cos_angle:\n",
    "        return phi_cos\n",
    "    else:\n",
    "        if cos_bound > 0.0:\n",
    "            bound = 1.0 - cos_bound\n",
    "            return acos_linear_extrapolation(phi_cos, (-bound, bound))\n",
    "        else:\n",
    "            return torch.acos(phi_cos)\n",
    "\n",
    "\n",
    "def so3_exp_map(log_rot: torch.Tensor, eps: float = 0.0001) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a batch of logarithmic representations of rotation matrices `log_rot`\n",
    "    to a batch of 3x3 rotation matrices using Rodrigues formula [1].\n",
    "\n",
    "    In the logarithmic representation, each rotation matrix is represented as\n",
    "    a 3-dimensional vector (`log_rot`) who's l2-norm and direction correspond\n",
    "    to the magnitude of the rotation angle and the axis of rotation respectively.\n",
    "\n",
    "    The conversion has a singularity around `log(R) = 0`\n",
    "    which is handled by clamping controlled with the `eps` argument.\n",
    "\n",
    "    Args:\n",
    "        log_rot: Batch of vectors of shape `(minibatch, 3)`.\n",
    "        eps: A float constant handling the conversion singularity.\n",
    "\n",
    "    Returns:\n",
    "        Batch of rotation matrices of shape `(minibatch, 3, 3)`.\n",
    "\n",
    "    Raises:\n",
    "        ValueError if `log_rot` is of incorrect shape.\n",
    "\n",
    "    [1] https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula\n",
    "    \"\"\"\n",
    "    return _so3_exp_map(log_rot, eps=eps)[0]\n",
    "\n",
    "\n",
    "def so3_exponential_map(log_rot: torch.Tensor, eps: float = 0.0001) -> torch.Tensor:\n",
    "    warnings.warn(\n",
    "        \"\"\"so3_exponential_map is deprecated,\n",
    "        Use so3_exp_map instead.\n",
    "        so3_exponential_map will be removed in future releases.\"\"\",\n",
    "        PendingDeprecationWarning,\n",
    "    )\n",
    "\n",
    "    return so3_exp_map(log_rot, eps)\n",
    "\n",
    "\n",
    "def _so3_exp_map(\n",
    "    log_rot: torch.Tensor, eps: float = 0.0001\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    A helper function that computes the so3 exponential map and,\n",
    "    apart from the rotation matrix, also returns intermediate variables\n",
    "    that can be re-used in other functions.\n",
    "    \"\"\"\n",
    "    _, dim = log_rot.shape\n",
    "    if dim != 3:\n",
    "        raise ValueError(\"Input tensor shape has to be Nx3.\")\n",
    "\n",
    "    nrms = (log_rot * log_rot).sum(1)\n",
    "    # phis ... rotation angles\n",
    "    rot_angles = torch.clamp(nrms, eps).sqrt()\n",
    "    skews = hat(log_rot)\n",
    "    skews_square = torch.bmm(skews, skews)\n",
    "\n",
    "    R = axis_angle_to_matrix(log_rot)\n",
    "\n",
    "    return R, rot_angles, skews, skews_square\n",
    "\n",
    "\n",
    "def so3_log_map(\n",
    "    R: torch.Tensor, eps: float = 0.0001, cos_bound: float = 1e-4\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a batch of 3x3 rotation matrices `R`\n",
    "    to a batch of 3-dimensional matrix logarithms of rotation matrices\n",
    "    The conversion has a singularity around `(R=I)`.\n",
    "\n",
    "    Args:\n",
    "        R: batch of rotation matrices of shape `(minibatch, 3, 3)`.\n",
    "        eps: (unused, for backward compatibility)\n",
    "        cos_bound: (unused, for backward compatibility)\n",
    "\n",
    "    Returns:\n",
    "        Batch of logarithms of input rotation matrices\n",
    "        of shape `(minibatch, 3)`.\n",
    "    \"\"\"\n",
    "\n",
    "    N, dim1, dim2 = R.shape\n",
    "    if dim1 != 3 or dim2 != 3:\n",
    "        raise ValueError(\"Input has to be a batch of 3x3 Tensors.\")\n",
    "\n",
    "    return matrix_to_axis_angle(R)\n",
    "\n",
    "\n",
    "def hat_inv(h: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the inverse Hat operator [1] of a batch of 3x3 matrices.\n",
    "\n",
    "    Args:\n",
    "        h: Batch of skew-symmetric matrices of shape `(minibatch, 3, 3)`.\n",
    "\n",
    "    Returns:\n",
    "        Batch of 3d vectors of shape `(minibatch, 3, 3)`.\n",
    "\n",
    "    Raises:\n",
    "        ValueError if `h` is of incorrect shape.\n",
    "        ValueError if `h` not skew-symmetric.\n",
    "\n",
    "    [1] https://en.wikipedia.org/wiki/Hat_operator\n",
    "    \"\"\"\n",
    "\n",
    "    N, dim1, dim2 = h.shape\n",
    "    if dim1 != 3 or dim2 != 3:\n",
    "        raise ValueError(\"Input has to be a batch of 3x3 Tensors.\")\n",
    "\n",
    "    ss_diff = torch.abs(h + h.permute(0, 2, 1)).max()\n",
    "\n",
    "    HAT_INV_SKEW_SYMMETRIC_TOL = 1e-5\n",
    "    if float(ss_diff) > HAT_INV_SKEW_SYMMETRIC_TOL:\n",
    "        raise ValueError(\"One of input matrices is not skew-symmetric.\")\n",
    "\n",
    "    x = h[:, 2, 1]\n",
    "    y = h[:, 0, 2]\n",
    "    z = h[:, 1, 0]\n",
    "\n",
    "    v = torch.stack((x, y, z), dim=1)\n",
    "\n",
    "    return v\n",
    "\n",
    "\n",
    "def hat(v: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the Hat operator [1] of a batch of 3D vectors.\n",
    "\n",
    "    Args:\n",
    "        v: Batch of vectors of shape `(minibatch , 3)`.\n",
    "\n",
    "    Returns:\n",
    "        Batch of skew-symmetric matrices of shape\n",
    "        `(minibatch, 3 , 3)` where each matrix is of the form:\n",
    "            `[    0  -v_z   v_y ]\n",
    "             [  v_z     0  -v_x ]\n",
    "             [ -v_y   v_x     0 ]`\n",
    "\n",
    "    Raises:\n",
    "        ValueError if `v` is of incorrect shape.\n",
    "\n",
    "    [1] https://en.wikipedia.org/wiki/Hat_operator\n",
    "    \"\"\"\n",
    "\n",
    "    N, dim = v.shape\n",
    "    if dim != 3:\n",
    "        raise ValueError(\"Input vectors have to be 3-dimensional.\")\n",
    "\n",
    "    h = torch.zeros((N, 3, 3), dtype=v.dtype, device=v.device)\n",
    "\n",
    "    x, y, z = v.unbind(1)\n",
    "\n",
    "    h[:, 0, 1] = -z\n",
    "    h[:, 0, 2] = y\n",
    "    h[:, 1, 0] = z\n",
    "    h[:, 1, 2] = -x\n",
    "    h[:, 2, 0] = -y\n",
    "    h[:, 2, 1] = x\n",
    "\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c8f9cf-151f-4cdc-94fb-4de73a9d4b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "# pytorch3d/transforms/se3.py\n",
    "\n",
    "\n",
    "def se3_exp_map(log_transform: torch.Tensor, eps: float = 1e-4) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a batch of logarithmic representations of SE(3) matrices `log_transform`\n",
    "    to a batch of 4x4 SE(3) matrices using the exponential map.\n",
    "    See e.g. [1], Sec 9.4.2. for more detailed description.\n",
    "\n",
    "    A SE(3) matrix has the following form:\n",
    "        ```\n",
    "        [ R 0 ]\n",
    "        [ T 1 ] ,\n",
    "        ```\n",
    "    where `R` is a 3x3 rotation matrix and `T` is a 3-D translation vector.\n",
    "    SE(3) matrices are commonly used to represent rigid motions or camera extrinsics.\n",
    "\n",
    "    In the SE(3) logarithmic representation SE(3) matrices are\n",
    "    represented as 6-dimensional vectors `[log_translation | log_rotation]`,\n",
    "    i.e. a concatenation of two 3D vectors `log_translation` and `log_rotation`.\n",
    "\n",
    "    The conversion from the 6D representation to a 4x4 SE(3) matrix `transform`\n",
    "    is done as follows:\n",
    "        ```\n",
    "        transform = exp( [ hat(log_rotation) 0 ]\n",
    "                         [   log_translation 1 ] ) ,\n",
    "        ```\n",
    "    where `exp` is the matrix exponential and `hat` is the Hat operator [2].\n",
    "\n",
    "    Note that for any `log_transform` with `0 <= ||log_rotation|| < 2pi`\n",
    "    (i.e. the rotation angle is between 0 and 2pi), the following identity holds:\n",
    "    ```\n",
    "    se3_log_map(se3_exponential_map(log_transform)) == log_transform\n",
    "    ```\n",
    "\n",
    "    The conversion has a singularity around `||log(transform)|| = 0`\n",
    "    which is handled by clamping controlled with the `eps` argument.\n",
    "\n",
    "    Args:\n",
    "        log_transform: Batch of vectors of shape `(minibatch, 6)`.\n",
    "        eps: A threshold for clipping the squared norm of the rotation logarithm\n",
    "            to avoid unstable gradients in the singular case.\n",
    "\n",
    "    Returns:\n",
    "        Batch of transformation matrices of shape `(minibatch, 4, 4)`.\n",
    "\n",
    "    Raises:\n",
    "        ValueError if `log_transform` is of incorrect shape.\n",
    "\n",
    "    [1] https://jinyongjeong.github.io/Download/SE3/jlblanco2010geometry3d_techrep.pdf\n",
    "    [2] https://en.wikipedia.org/wiki/Hat_operator\n",
    "    \"\"\"\n",
    "\n",
    "    if log_transform.ndim != 2 or log_transform.shape[1] != 6:\n",
    "        raise ValueError(\"Expected input to be of shape (N, 6).\")\n",
    "\n",
    "    N, _ = log_transform.shape\n",
    "\n",
    "    log_translation = log_transform[..., :3]\n",
    "    log_rotation = log_transform[..., 3:]\n",
    "\n",
    "    # rotation is an exponential map of log_rotation\n",
    "    (\n",
    "        R,\n",
    "        rotation_angles,\n",
    "        log_rotation_hat,\n",
    "        log_rotation_hat_square,\n",
    "    ) = _so3_exp_map(log_rotation, eps=eps)\n",
    "\n",
    "    # translation is V @ T\n",
    "    V = _se3_V_matrix(\n",
    "        log_rotation,\n",
    "        log_rotation_hat,\n",
    "        log_rotation_hat_square,\n",
    "        rotation_angles,\n",
    "        eps=eps,\n",
    "    )\n",
    "    T = torch.bmm(V, log_translation[:, :, None])[:, :, 0]\n",
    "\n",
    "    transform = torch.zeros(\n",
    "        N, 4, 4, dtype=log_transform.dtype, device=log_transform.device\n",
    "    )\n",
    "\n",
    "    transform[:, :3, :3] = R\n",
    "    transform[:, :3, 3] = T\n",
    "    transform[:, 3, 3] = 1.0\n",
    "\n",
    "    return transform.permute(0, 2, 1)\n",
    "\n",
    "\n",
    "def se3_log_map(\n",
    "    transform: torch.Tensor, eps: float = 1e-4, cos_bound: float = 1e-4\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a batch of 4x4 transformation matrices `transform`\n",
    "    to a batch of 6-dimensional SE(3) logarithms of the SE(3) matrices.\n",
    "    See e.g. [1], Sec 9.4.2. for more detailed description.\n",
    "\n",
    "    A SE(3) matrix has the following form:\n",
    "        ```\n",
    "        [ R 0 ]\n",
    "        [ T 1 ] ,\n",
    "        ```\n",
    "    where `R` is an orthonormal 3x3 rotation matrix and `T` is a 3-D translation vector.\n",
    "    SE(3) matrices are commonly used to represent rigid motions or camera extrinsics.\n",
    "\n",
    "    In the SE(3) logarithmic representation SE(3) matrices are\n",
    "    represented as 6-dimensional vectors `[log_translation | log_rotation]`,\n",
    "    i.e. a concatenation of two 3D vectors `log_translation` and `log_rotation`.\n",
    "\n",
    "    The conversion from the 4x4 SE(3) matrix `transform` to the\n",
    "    6D representation `log_transform = [log_translation | log_rotation]`\n",
    "    is done as follows:\n",
    "        ```\n",
    "        log_transform = log(transform)\n",
    "        log_translation = log_transform[3, :3]\n",
    "        log_rotation = inv_hat(log_transform[:3, :3])\n",
    "        ```\n",
    "    where `log` is the matrix logarithm\n",
    "    and `inv_hat` is the inverse of the Hat operator [2].\n",
    "\n",
    "    Note that for any valid 4x4 `transform` matrix, the following identity holds:\n",
    "    ```\n",
    "    se3_exp_map(se3_log_map(transform)) == transform\n",
    "    ```\n",
    "\n",
    "    The conversion has a singularity around `(transform=I)` which is handled\n",
    "    by clamping controlled with the `eps` and `cos_bound` arguments.\n",
    "\n",
    "    Args:\n",
    "        transform: batch of SE(3) matrices of shape `(minibatch, 4, 4)`.\n",
    "        eps: A threshold for clipping the squared norm of the rotation logarithm\n",
    "            to avoid division by zero in the singular case.\n",
    "        cos_bound: Clamps the cosine of the rotation angle to\n",
    "            [-1 + cos_bound, 3 - cos_bound] to avoid non-finite outputs.\n",
    "            The non-finite outputs can be caused by passing small rotation angles\n",
    "            to the `acos` function in `so3_rotation_angle` of `so3_log_map`.\n",
    "\n",
    "    Returns:\n",
    "        Batch of logarithms of input SE(3) matrices\n",
    "        of shape `(minibatch, 6)`.\n",
    "\n",
    "    Raises:\n",
    "        ValueError if `transform` is of incorrect shape.\n",
    "        ValueError if `R` has an unexpected trace.\n",
    "\n",
    "    [1] https://jinyongjeong.github.io/Download/SE3/jlblanco2010geometry3d_techrep.pdf\n",
    "    [2] https://en.wikipedia.org/wiki/Hat_operator\n",
    "    \"\"\"\n",
    "\n",
    "    if transform.ndim != 3:\n",
    "        raise ValueError(\"Input tensor shape has to be (N, 4, 4).\")\n",
    "\n",
    "    N, dim1, dim2 = transform.shape\n",
    "    if dim1 != 4 or dim2 != 4:\n",
    "        raise ValueError(\"Input tensor shape has to be (N, 4, 4).\")\n",
    "\n",
    "    if not torch.allclose(transform[:, :3, 3], torch.zeros_like(transform[:, :3, 3])):\n",
    "        raise ValueError(\"All elements of `transform[:, :3, 3]` should be 0.\")\n",
    "\n",
    "    # log_rot is just so3_log_map of the upper left 3x3 block\n",
    "    R = transform[:, :3, :3].permute(0, 2, 1)\n",
    "    log_rotation = so3_log_map(R, eps=eps, cos_bound=cos_bound)\n",
    "\n",
    "    # log_translation is V^-1 @ T\n",
    "    T = transform[:, 3, :3]\n",
    "    V = _se3_V_matrix(*_get_se3_V_input(log_rotation), eps=eps)\n",
    "    log_translation = torch.linalg.solve(V, T[:, :, None])[:, :, 0]\n",
    "\n",
    "    return torch.cat((log_translation, log_rotation), dim=1)\n",
    "\n",
    "\n",
    "def _se3_V_matrix(\n",
    "    log_rotation: torch.Tensor,\n",
    "    log_rotation_hat: torch.Tensor,\n",
    "    log_rotation_hat_square: torch.Tensor,\n",
    "    rotation_angles: torch.Tensor,\n",
    "    eps: float = 1e-4,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    A helper function that computes the \"V\" matrix from [1], Sec 9.4.2.\n",
    "    [1] https://jinyongjeong.github.io/Download/SE3/jlblanco2010geometry3d_techrep.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    V = (\n",
    "        torch.eye(3, dtype=log_rotation.dtype, device=log_rotation.device)[None]\n",
    "        + log_rotation_hat\n",
    "        # pyre-fixme[58]: `**` is not supported for operand types `Tensor` and `int`.\n",
    "        * ((1 - torch.cos(rotation_angles)) / (rotation_angles**2))[:, None, None]\n",
    "        + (\n",
    "            log_rotation_hat_square\n",
    "            # pyre-fixme[58]: `**` is not supported for operand types `Tensor` and\n",
    "            #  `int`.\n",
    "            * ((rotation_angles - torch.sin(rotation_angles)) / (rotation_angles**3))[\n",
    "                :, None, None\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return V\n",
    "\n",
    "\n",
    "def _get_se3_V_input(log_rotation: torch.Tensor, eps: float = 1e-4):\n",
    "    \"\"\"\n",
    "    A helper function that computes the input variables to the `_se3_V_matrix`\n",
    "    function.\n",
    "    \"\"\"\n",
    "    # pyre-fixme[58]: `**` is not supported for operand types `Tensor` and `int`.\n",
    "    nrms = (log_rotation**2).sum(-1)\n",
    "    rotation_angles = torch.clamp(nrms, eps).sqrt()\n",
    "    log_rotation_hat = hat(log_rotation)\n",
    "    log_rotation_hat_square = torch.bmm(log_rotation_hat, log_rotation_hat)\n",
    "    return log_rotation, log_rotation_hat, log_rotation_hat_square, rotation_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98dcc88-18cb-463f-9884-80a07e6a1e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "# pytorch3d/transforms/transform3d.py\n",
    "\n",
    "import math\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def make_device(device: Device) -> torch.device:\n",
    "    \"\"\"\n",
    "    Makes an actual torch.device object from the device specified as\n",
    "    either a string or torch.device object. If the device is `cuda` without\n",
    "    a specific index, the index of the current device is assigned.\n",
    "\n",
    "    Args:\n",
    "        device: Device (as str or torch.device)\n",
    "\n",
    "    Returns:\n",
    "        A matching torch.device object\n",
    "    \"\"\"\n",
    "    device = torch.device(device) if isinstance(device, str) else device\n",
    "    if device.type == \"cuda\" and device.index is None:\n",
    "        # If cuda but with no index, then the current cuda device is indicated.\n",
    "        # In that case, we fix to that device\n",
    "        device = torch.device(f\"cuda:{torch.cuda.current_device()}\")\n",
    "    return device\n",
    "\n",
    "\n",
    "def get_device(x, device: Optional[Device] = None) -> torch.device:\n",
    "    \"\"\"\n",
    "    Gets the device of the specified variable x if it is a tensor, or\n",
    "    falls back to a default CPU device otherwise. Allows overriding by\n",
    "    providing an explicit device.\n",
    "\n",
    "    Args:\n",
    "        x: a torch.Tensor to get the device from or another type\n",
    "        device: Device (as str or torch.device) to fall back to\n",
    "\n",
    "    Returns:\n",
    "        A matching torch.device object\n",
    "    \"\"\"\n",
    "\n",
    "    # User overrides device\n",
    "    if device is not None:\n",
    "        return make_device(device)\n",
    "\n",
    "    # Set device based on input tensor\n",
    "    if torch.is_tensor(x):\n",
    "        return x.device\n",
    "\n",
    "    # Default device is cpu\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def _safe_det_3x3(t: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Fast determinant calculation for a batch of 3x3 matrices.\n",
    "\n",
    "    Note, result of this function might not be the same as `torch.det()`.\n",
    "    The differences might be in the last significant digit.\n",
    "\n",
    "    Args:\n",
    "        t: Tensor of shape (N, 3, 3).\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape (N) with determinants.\n",
    "    \"\"\"\n",
    "\n",
    "    det = (\n",
    "        t[..., 0, 0] * (t[..., 1, 1] * t[..., 2, 2] - t[..., 1, 2] * t[..., 2, 1])\n",
    "        - t[..., 0, 1] * (t[..., 1, 0] * t[..., 2, 2] - t[..., 2, 0] * t[..., 1, 2])\n",
    "        + t[..., 0, 2] * (t[..., 1, 0] * t[..., 2, 1] - t[..., 2, 0] * t[..., 1, 1])\n",
    "    )\n",
    "\n",
    "    return det\n",
    "\n",
    "\n",
    "class Transform3d:\n",
    "    \"\"\"\n",
    "    A Transform3d object encapsulates a batch of N 3D transformations, and knows\n",
    "    how to transform points and normal vectors. Suppose that t is a Transform3d;\n",
    "    then we can do the following:\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        N = len(t)\n",
    "        points = torch.randn(N, P, 3)\n",
    "        normals = torch.randn(N, P, 3)\n",
    "        points_transformed = t.transform_points(points)    # => (N, P, 3)\n",
    "        normals_transformed = t.transform_normals(normals)  # => (N, P, 3)\n",
    "\n",
    "\n",
    "    BROADCASTING\n",
    "    Transform3d objects supports broadcasting. Suppose that t1 and tN are\n",
    "    Transform3d objects with len(t1) == 1 and len(tN) == N respectively. Then we\n",
    "    can broadcast transforms like this:\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        t1.transform_points(torch.randn(P, 3))     # => (P, 3)\n",
    "        t1.transform_points(torch.randn(1, P, 3))  # => (1, P, 3)\n",
    "        t1.transform_points(torch.randn(M, P, 3))  # => (M, P, 3)\n",
    "        tN.transform_points(torch.randn(P, 3))     # => (N, P, 3)\n",
    "        tN.transform_points(torch.randn(1, P, 3))  # => (N, P, 3)\n",
    "\n",
    "\n",
    "    COMBINING TRANSFORMS\n",
    "    Transform3d objects can be combined in two ways: composing and stacking.\n",
    "    Composing is function composition. Given Transform3d objects t1, t2, t3,\n",
    "    the following all compute the same thing:\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        y1 = t3.transform_points(t2.transform_points(t1.transform_points(x)))\n",
    "        y2 = t1.compose(t2).compose(t3).transform_points(x)\n",
    "        y3 = t1.compose(t2, t3).transform_points(x)\n",
    "\n",
    "\n",
    "    Composing transforms should broadcast.\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        if len(t1) == 1 and len(t2) == N, then len(t1.compose(t2)) == N.\n",
    "\n",
    "    We can also stack a sequence of Transform3d objects, which represents\n",
    "    composition along the batch dimension; then the following should compute the\n",
    "    same thing.\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        N, M = len(tN), len(tM)\n",
    "        xN = torch.randn(N, P, 3)\n",
    "        xM = torch.randn(M, P, 3)\n",
    "        y1 = torch.cat([tN.transform_points(xN), tM.transform_points(xM)], dim=0)\n",
    "        y2 = tN.stack(tM).transform_points(torch.cat([xN, xM], dim=0))\n",
    "\n",
    "    BUILDING TRANSFORMS\n",
    "    We provide convenience methods for easily building Transform3d objects\n",
    "    as compositions of basic transforms.\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        # Scale by 0.5, then translate by (1, 2, 3)\n",
    "        t1 = Transform3d().scale(0.5).translate(1, 2, 3)\n",
    "\n",
    "        # Scale each axis by a different amount, then translate, then scale\n",
    "        t2 = Transform3d().scale(1, 3, 3).translate(2, 3, 1).scale(2.0)\n",
    "\n",
    "        t3 = t1.compose(t2)\n",
    "        tN = t1.stack(t3, t3)\n",
    "\n",
    "\n",
    "    BACKPROP THROUGH TRANSFORMS\n",
    "    When building transforms, we can also parameterize them by Torch tensors;\n",
    "    in this case we can backprop through the construction and application of\n",
    "    Transform objects, so they could be learned via gradient descent or\n",
    "    predicted by a neural network.\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        s1_params = torch.randn(N, requires_grad=True)\n",
    "        t_params = torch.randn(N, 3, requires_grad=True)\n",
    "        s2_params = torch.randn(N, 3, requires_grad=True)\n",
    "\n",
    "        t = Transform3d().scale(s1_params).translate(t_params).scale(s2_params)\n",
    "        x = torch.randn(N, 3)\n",
    "        y = t.transform_points(x)\n",
    "        loss = compute_loss(y)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            s1_params -= lr * s1_params.grad\n",
    "            t_params -= lr * t_params.grad\n",
    "            s2_params -= lr * s2_params.grad\n",
    "\n",
    "    CONVENTIONS\n",
    "    We adopt a right-hand coordinate system, meaning that rotation about an axis\n",
    "    with a positive angle results in a counter clockwise rotation.\n",
    "\n",
    "    This class assumes that transformations are applied on inputs which\n",
    "    are row vectors. The internal representation of the Nx4x4 transformation\n",
    "    matrix is of the form:\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        M = [\n",
    "                [Rxx, Ryx, Rzx, 0],\n",
    "                [Rxy, Ryy, Rzy, 0],\n",
    "                [Rxz, Ryz, Rzz, 0],\n",
    "                [Tx,  Ty,  Tz,  1],\n",
    "            ]\n",
    "\n",
    "    To apply the transformation to points, which are row vectors, the latter are\n",
    "    converted to homogeneous (4D) coordinates and right-multiplied by the M matrix:\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        points = [[0, 1, 2]]  # (1 x 3) xyz coordinates of a point\n",
    "        [transformed_points, 1] ∝ [points, 1] @ M\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dtype: torch.dtype = torch.float32,\n",
    "        device: Device = \"cpu\",\n",
    "        matrix: Optional[torch.Tensor] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dtype: The data type of the transformation matrix.\n",
    "                to be used if `matrix = None`.\n",
    "            device: The device for storing the implemented transformation.\n",
    "                If `matrix != None`, uses the device of input `matrix`.\n",
    "            matrix: A tensor of shape (4, 4) or of shape (minibatch, 4, 4)\n",
    "                representing the 4x4 3D transformation matrix.\n",
    "                If `None`, initializes with identity using\n",
    "                the specified `device` and `dtype`.\n",
    "        \"\"\"\n",
    "\n",
    "        if matrix is None:\n",
    "            self._matrix = torch.eye(4, dtype=dtype, device=device).view(1, 4, 4)\n",
    "        else:\n",
    "            if matrix.ndim not in (2, 3):\n",
    "                raise ValueError('\"matrix\" has to be a 2- or a 3-dimensional tensor.')\n",
    "            if matrix.shape[-2] != 4 or matrix.shape[-1] != 4:\n",
    "                raise ValueError(\n",
    "                    '\"matrix\" has to be a tensor of shape (minibatch, 4, 4) or (4, 4).'\n",
    "                )\n",
    "            # set dtype and device from matrix\n",
    "            dtype = matrix.dtype\n",
    "            device = matrix.device\n",
    "            self._matrix = matrix.view(-1, 4, 4)\n",
    "\n",
    "        self._transforms = []  # store transforms to compose\n",
    "        self._lu = None\n",
    "        self.device = make_device(device)\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.get_matrix().shape[0]\n",
    "\n",
    "    def __getitem__(\n",
    "        self, index: Union[int, List[int], slice, torch.BoolTensor, torch.LongTensor]\n",
    "    ) -> \"Transform3d\":\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index: Specifying the index of the transform to retrieve.\n",
    "                Can be an int, slice, list of ints, boolean, long tensor.\n",
    "                Supports negative indices.\n",
    "\n",
    "        Returns:\n",
    "            Transform3d object with selected transforms. The tensors are not cloned.\n",
    "        \"\"\"\n",
    "        if isinstance(index, int):\n",
    "            index = [index]\n",
    "        return self.__class__(matrix=self.get_matrix()[index])\n",
    "\n",
    "    def compose(self, *others: \"Transform3d\") -> \"Transform3d\":\n",
    "        \"\"\"\n",
    "        Return a new Transform3d representing the composition of self with the\n",
    "        given other transforms, which will be stored as an internal list.\n",
    "\n",
    "        Args:\n",
    "            *others: Any number of Transform3d objects\n",
    "\n",
    "        Returns:\n",
    "            A new Transform3d with the stored transforms\n",
    "        \"\"\"\n",
    "        out = Transform3d(dtype=self.dtype, device=self.device)\n",
    "        out._matrix = self._matrix.clone()\n",
    "        for other in others:\n",
    "            if not isinstance(other, Transform3d):\n",
    "                msg = \"Only possible to compose Transform3d objects; got %s\"\n",
    "                raise ValueError(msg % type(other))\n",
    "        out._transforms = self._transforms + list(others)\n",
    "        return out\n",
    "\n",
    "    def get_matrix(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns a 4×4 matrix corresponding to each transform in the batch.\n",
    "\n",
    "        If the transform was composed from others, the matrix for the composite\n",
    "        transform will be returned.\n",
    "        For example, if self.transforms contains transforms t1, t2, and t3, and\n",
    "        given a set of points x, the following should be true:\n",
    "\n",
    "        .. code-block:: python\n",
    "\n",
    "            y1 = t1.compose(t2, t3).transform(x)\n",
    "            y2 = t3.transform(t2.transform(t1.transform(x)))\n",
    "            y1.get_matrix() == y2.get_matrix()\n",
    "\n",
    "        Where necessary, those transforms are broadcast against each other.\n",
    "\n",
    "        Returns:\n",
    "            A (N, 4, 4) batch of transformation matrices representing\n",
    "                the stored transforms. See the class documentation for the conventions.\n",
    "        \"\"\"\n",
    "        composed_matrix = self._matrix.clone()\n",
    "        if len(self._transforms) > 0:\n",
    "            for other in self._transforms:\n",
    "                other_matrix = other.get_matrix()\n",
    "                composed_matrix = _broadcast_bmm(composed_matrix, other_matrix)\n",
    "        return composed_matrix\n",
    "\n",
    "    def get_se3_log(self, eps: float = 1e-4, cos_bound: float = 1e-4) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns a 6D SE(3) log vector corresponding to each transform in the batch.\n",
    "\n",
    "        In the SE(3) logarithmic representation SE(3) matrices are\n",
    "        represented as 6-dimensional vectors `[log_translation | log_rotation]`,\n",
    "        i.e. a concatenation of two 3D vectors `log_translation` and `log_rotation`.\n",
    "\n",
    "        The conversion from the 4x4 SE(3) matrix `transform` to the\n",
    "        6D representation `log_transform = [log_translation | log_rotation]`\n",
    "        is done as follows::\n",
    "\n",
    "            log_transform = log(transform.get_matrix())\n",
    "            log_translation = log_transform[3, :3]\n",
    "            log_rotation = inv_hat(log_transform[:3, :3])\n",
    "\n",
    "        where `log` is the matrix logarithm\n",
    "        and `inv_hat` is the inverse of the Hat operator [2].\n",
    "\n",
    "        See the docstring for `se3.se3_log_map` and [1], Sec 9.4.2. for more\n",
    "        detailed description.\n",
    "\n",
    "        Args:\n",
    "            eps: A threshold for clipping the squared norm of the rotation logarithm\n",
    "                to avoid division by zero in the singular case.\n",
    "            cos_bound: Clamps the cosine of the rotation angle to\n",
    "                [-1 + cos_bound, 3 - cos_bound] to avoid non-finite outputs.\n",
    "                The non-finite outputs can be caused by passing small rotation angles\n",
    "                to the `acos` function in `so3_rotation_angle` of `so3_log_map`.\n",
    "\n",
    "        Returns:\n",
    "            A (N, 6) tensor, rows of which represent the individual transforms\n",
    "            stored in the object as SE(3) logarithms.\n",
    "\n",
    "        Raises:\n",
    "            ValueError if the stored transform is not Euclidean (e.g. R is not a rotation\n",
    "                matrix or the last column has non-zeros in the first three places).\n",
    "\n",
    "        [1] https://jinyongjeong.github.io/Download/SE3/jlblanco2010geometry3d_techrep.pdf\n",
    "        [2] https://en.wikipedia.org/wiki/Hat_operator\n",
    "        \"\"\"\n",
    "        return se3_log_map(self.get_matrix(), eps, cos_bound)\n",
    "\n",
    "    def _get_matrix_inverse(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Return the inverse of self._matrix.\n",
    "        \"\"\"\n",
    "        return torch.inverse(self._matrix)\n",
    "\n",
    "    def inverse(self, invert_composed: bool = False) -> \"Transform3d\":\n",
    "        \"\"\"\n",
    "        Returns a new Transform3d object that represents an inverse of the\n",
    "        current transformation.\n",
    "\n",
    "        Args:\n",
    "            invert_composed:\n",
    "                - True: First compose the list of stored transformations\n",
    "                  and then apply inverse to the result. This is\n",
    "                  potentially slower for classes of transformations\n",
    "                  with inverses that can be computed efficiently\n",
    "                  (e.g. rotations and translations).\n",
    "                - False: Invert the individual stored transformations\n",
    "                  independently without composing them.\n",
    "\n",
    "        Returns:\n",
    "            A new Transform3d object containing the inverse of the original\n",
    "            transformation.\n",
    "        \"\"\"\n",
    "\n",
    "        tinv = Transform3d(dtype=self.dtype, device=self.device)\n",
    "\n",
    "        if invert_composed:\n",
    "            # first compose then invert\n",
    "            tinv._matrix = torch.inverse(self.get_matrix())\n",
    "        else:\n",
    "            # self._get_matrix_inverse() implements efficient inverse\n",
    "            # of self._matrix\n",
    "            i_matrix = self._get_matrix_inverse()\n",
    "\n",
    "            # 2 cases:\n",
    "            if len(self._transforms) > 0:\n",
    "                # a) Either we have a non-empty list of transforms:\n",
    "                # Here we take self._matrix and append its inverse at the\n",
    "                # end of the reverted _transforms list. After composing\n",
    "                # the transformations with get_matrix(), this correctly\n",
    "                # right-multiplies by the inverse of self._matrix\n",
    "                # at the end of the composition.\n",
    "                tinv._transforms = [t.inverse() for t in reversed(self._transforms)]\n",
    "                last = Transform3d(dtype=self.dtype, device=self.device)\n",
    "                last._matrix = i_matrix\n",
    "                tinv._transforms.append(last)\n",
    "            else:\n",
    "                # b) Or there are no stored transformations\n",
    "                # we just set inverted matrix\n",
    "                tinv._matrix = i_matrix\n",
    "\n",
    "        return tinv\n",
    "\n",
    "    def stack(self, *others: \"Transform3d\") -> \"Transform3d\":\n",
    "        \"\"\"\n",
    "        Return a new batched Transform3d representing the batch elements from\n",
    "        self and all the given other transforms all batched together.\n",
    "\n",
    "        Args:\n",
    "            *others: Any number of Transform3d objects\n",
    "\n",
    "        Returns:\n",
    "            A new Transform3d.\n",
    "        \"\"\"\n",
    "        transforms = [self] + list(others)\n",
    "        matrix = torch.cat([t.get_matrix() for t in transforms], dim=0)\n",
    "        out = Transform3d(dtype=self.dtype, device=self.device)\n",
    "        out._matrix = matrix\n",
    "        return out\n",
    "\n",
    "    def transform_points(self, points, eps: Optional[float] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Use this transform to transform a set of 3D points. Assumes row major\n",
    "        ordering of the input points.\n",
    "\n",
    "        Args:\n",
    "            points: Tensor of shape (P, 3) or (N, P, 3)\n",
    "            eps: If eps!=None, the argument is used to clamp the\n",
    "                last coordinate before performing the final division.\n",
    "                The clamping corresponds to:\n",
    "                last_coord := (last_coord.sign() + (last_coord==0)) *\n",
    "                torch.clamp(last_coord.abs(), eps),\n",
    "                i.e. the last coordinates that are exactly 0 will\n",
    "                be clamped to +eps.\n",
    "\n",
    "        Returns:\n",
    "            points_out: points of shape (N, P, 3) or (P, 3) depending\n",
    "            on the dimensions of the transform\n",
    "        \"\"\"\n",
    "        points_batch = points.clone()\n",
    "        if points_batch.dim() == 2:\n",
    "            points_batch = points_batch[None]  # (P, 3) -> (1, P, 3)\n",
    "        if points_batch.dim() != 3:\n",
    "            msg = \"Expected points to have dim = 2 or dim = 3: got shape %r\"\n",
    "            raise ValueError(msg % repr(points.shape))\n",
    "\n",
    "        N, P, _3 = points_batch.shape\n",
    "        ones = torch.ones(N, P, 1, dtype=points.dtype, device=points.device)\n",
    "        points_batch = torch.cat([points_batch, ones], dim=2)\n",
    "\n",
    "        composed_matrix = self.get_matrix()\n",
    "        points_out = _broadcast_bmm(points_batch, composed_matrix)\n",
    "        denom = points_out[..., 3:]  # denominator\n",
    "        if eps is not None:\n",
    "            denom_sign = denom.sign() + (denom == 0.0).type_as(denom)\n",
    "            denom = denom_sign * torch.clamp(denom.abs(), eps)\n",
    "        points_out = points_out[..., :3] / denom\n",
    "\n",
    "        # When transform is (1, 4, 4) and points is (P, 3) return\n",
    "        # points_out of shape (P, 3)\n",
    "        if points_out.shape[0] == 1 and points.dim() == 2:\n",
    "            points_out = points_out.reshape(points.shape)\n",
    "\n",
    "        return points_out\n",
    "\n",
    "    def transform_normals(self, normals) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Use this transform to transform a set of normal vectors.\n",
    "\n",
    "        Args:\n",
    "            normals: Tensor of shape (P, 3) or (N, P, 3)\n",
    "\n",
    "        Returns:\n",
    "            normals_out: Tensor of shape (P, 3) or (N, P, 3) depending\n",
    "            on the dimensions of the transform\n",
    "        \"\"\"\n",
    "        if normals.dim() not in [2, 3]:\n",
    "            msg = \"Expected normals to have dim = 2 or dim = 3: got shape %r\"\n",
    "            raise ValueError(msg % (normals.shape,))\n",
    "        composed_matrix = self.get_matrix()\n",
    "\n",
    "        # TODO: inverse is bad! Solve a linear system instead\n",
    "        mat = composed_matrix[:, :3, :3]\n",
    "        normals_out = _broadcast_bmm(normals, mat.transpose(1, 2).inverse())\n",
    "\n",
    "        # This doesn't pass unit tests. TODO investigate further\n",
    "        # if self._lu is None:\n",
    "        #     self._lu = self._matrix[:, :3, :3].transpose(1, 2).lu()\n",
    "        # normals_out = normals.lu_solve(*self._lu)\n",
    "\n",
    "        # When transform is (1, 4, 4) and normals is (P, 3) return\n",
    "        # normals_out of shape (P, 3)\n",
    "        if normals_out.shape[0] == 1 and normals.dim() == 2:\n",
    "            normals_out = normals_out.reshape(normals.shape)\n",
    "\n",
    "        return normals_out\n",
    "\n",
    "    def translate(self, *args, **kwargs) -> \"Transform3d\":\n",
    "        return self.compose(\n",
    "            Translate(*args, device=self.device, dtype=self.dtype, **kwargs)\n",
    "        )\n",
    "\n",
    "    def scale(self, *args, **kwargs) -> \"Transform3d\":\n",
    "        return self.compose(\n",
    "            Scale(*args, device=self.device, dtype=self.dtype, **kwargs)\n",
    "        )\n",
    "\n",
    "    def rotate(self, *args, **kwargs) -> \"Transform3d\":\n",
    "        return self.compose(\n",
    "            Rotate(*args, device=self.device, dtype=self.dtype, **kwargs)\n",
    "        )\n",
    "\n",
    "    def rotate_axis_angle(self, *args, **kwargs) -> \"Transform3d\":\n",
    "        return self.compose(\n",
    "            RotateAxisAngle(*args, device=self.device, dtype=self.dtype, **kwargs)\n",
    "        )\n",
    "\n",
    "    def clone(self) -> \"Transform3d\":\n",
    "        \"\"\"\n",
    "        Deep copy of Transforms object. All internal tensors are cloned\n",
    "        individually.\n",
    "\n",
    "        Returns:\n",
    "            new Transforms object.\n",
    "        \"\"\"\n",
    "        other = Transform3d(dtype=self.dtype, device=self.device)\n",
    "        if self._lu is not None:\n",
    "            other._lu = [elem.clone() for elem in self._lu]\n",
    "        other._matrix = self._matrix.clone()\n",
    "        other._transforms = [t.clone() for t in self._transforms]\n",
    "        return other\n",
    "\n",
    "    def to(\n",
    "        self,\n",
    "        device: Device,\n",
    "        copy: bool = False,\n",
    "        dtype: Optional[torch.dtype] = None,\n",
    "    ) -> \"Transform3d\":\n",
    "        \"\"\"\n",
    "        Match functionality of torch.Tensor.to()\n",
    "        If copy = True or the self Tensor is on a different device, the\n",
    "        returned tensor is a copy of self with the desired torch.device.\n",
    "        If copy = False and the self Tensor already has the correct torch.device,\n",
    "        then self is returned.\n",
    "\n",
    "        Args:\n",
    "          device: Device (as str or torch.device) for the new tensor.\n",
    "          copy: Boolean indicator whether or not to clone self. Default False.\n",
    "          dtype: If not None, casts the internal tensor variables\n",
    "              to a given torch.dtype.\n",
    "\n",
    "        Returns:\n",
    "          Transform3d object.\n",
    "        \"\"\"\n",
    "        device_ = make_device(device)\n",
    "        dtype_ = self.dtype if dtype is None else dtype\n",
    "        skip_to = self.device == device_ and self.dtype == dtype_\n",
    "\n",
    "        if not copy and skip_to:\n",
    "            return self\n",
    "\n",
    "        other = self.clone()\n",
    "\n",
    "        if skip_to:\n",
    "            return other\n",
    "\n",
    "        other.device = device_\n",
    "        other.dtype = dtype_\n",
    "        other._matrix = other._matrix.to(device=device_, dtype=dtype_)\n",
    "        other._transforms = [\n",
    "            t.to(device_, copy=copy, dtype=dtype_) for t in other._transforms\n",
    "        ]\n",
    "        return other\n",
    "\n",
    "    def cpu(self) -> \"Transform3d\":\n",
    "        return self.to(\"cpu\")\n",
    "\n",
    "    def cuda(self) -> \"Transform3d\":\n",
    "        return self.to(\"cuda\")\n",
    "\n",
    "\n",
    "class Translate(Transform3d):\n",
    "    def __init__(\n",
    "        self,\n",
    "        x,\n",
    "        y=None,\n",
    "        z=None,\n",
    "        dtype: torch.dtype = torch.float32,\n",
    "        device: Optional[Device] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Create a new Transform3d representing 3D translations.\n",
    "\n",
    "        Option I: Translate(xyz, dtype=torch.float32, device='cpu')\n",
    "            xyz should be a tensor of shape (N, 3)\n",
    "\n",
    "        Option II: Translate(x, y, z, dtype=torch.float32, device='cpu')\n",
    "            Here x, y, and z will be broadcast against each other and\n",
    "            concatenated to form the translation. Each can be:\n",
    "                - A python scalar\n",
    "                - A torch scalar\n",
    "                - A 1D torch tensor\n",
    "        \"\"\"\n",
    "        xyz = _handle_input(x, y, z, dtype, device, \"Translate\")\n",
    "        super().__init__(device=xyz.device, dtype=dtype)\n",
    "        N = xyz.shape[0]\n",
    "\n",
    "        mat = torch.eye(4, dtype=dtype, device=self.device)\n",
    "        mat = mat.view(1, 4, 4).repeat(N, 1, 1)\n",
    "        mat[:, 3, :3] = xyz\n",
    "        self._matrix = mat\n",
    "\n",
    "    def _get_matrix_inverse(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Return the inverse of self._matrix.\n",
    "        \"\"\"\n",
    "        inv_mask = self._matrix.new_ones([1, 4, 4])\n",
    "        inv_mask[0, 3, :3] = -1.0\n",
    "        i_matrix = self._matrix * inv_mask\n",
    "        return i_matrix\n",
    "\n",
    "\n",
    "class Scale(Transform3d):\n",
    "    def __init__(\n",
    "        self,\n",
    "        x,\n",
    "        y=None,\n",
    "        z=None,\n",
    "        dtype: torch.dtype = torch.float32,\n",
    "        device: Optional[Device] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        A Transform3d representing a scaling operation, with different scale\n",
    "        factors along each coordinate axis.\n",
    "\n",
    "        Option I: Scale(s, dtype=torch.float32, device='cpu')\n",
    "            s can be one of\n",
    "                - Python scalar or torch scalar: Single uniform scale\n",
    "                - 1D torch tensor of shape (N,): A batch of uniform scale\n",
    "                - 2D torch tensor of shape (N, 3): Scale differently along each axis\n",
    "\n",
    "        Option II: Scale(x, y, z, dtype=torch.float32, device='cpu')\n",
    "            Each of x, y, and z can be one of\n",
    "                - python scalar\n",
    "                - torch scalar\n",
    "                - 1D torch tensor\n",
    "        \"\"\"\n",
    "        xyz = _handle_input(x, y, z, dtype, device, \"scale\", allow_singleton=True)\n",
    "        super().__init__(device=xyz.device, dtype=dtype)\n",
    "        N = xyz.shape[0]\n",
    "\n",
    "        # TODO: Can we do this all in one go somehow?\n",
    "        mat = torch.eye(4, dtype=dtype, device=self.device)\n",
    "        mat = mat.view(1, 4, 4).repeat(N, 1, 1)\n",
    "        mat[:, 0, 0] = xyz[:, 0]\n",
    "        mat[:, 1, 1] = xyz[:, 1]\n",
    "        mat[:, 2, 2] = xyz[:, 2]\n",
    "        self._matrix = mat\n",
    "\n",
    "    def _get_matrix_inverse(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Return the inverse of self._matrix.\n",
    "        \"\"\"\n",
    "        xyz = torch.stack([self._matrix[:, i, i] for i in range(4)], dim=1)\n",
    "        # pyre-fixme[58]: `/` is not supported for operand types `float` and `Tensor`.\n",
    "        ixyz = 1.0 / xyz\n",
    "        # pyre-fixme[6]: For 1st param expected `Tensor` but got `float`.\n",
    "        imat = torch.diag_embed(ixyz, dim1=1, dim2=2)\n",
    "        return imat\n",
    "\n",
    "\n",
    "class Rotate(Transform3d):\n",
    "    def __init__(\n",
    "        self,\n",
    "        R: torch.Tensor,\n",
    "        dtype: torch.dtype = torch.float32,\n",
    "        device: Optional[Device] = None,\n",
    "        orthogonal_tol: float = 1e-5,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Create a new Transform3d representing 3D rotation using a rotation\n",
    "        matrix as the input.\n",
    "\n",
    "        Args:\n",
    "            R: a tensor of shape (3, 3) or (N, 3, 3)\n",
    "            orthogonal_tol: tolerance for the test of the orthogonality of R\n",
    "\n",
    "        \"\"\"\n",
    "        device_ = get_device(R, device)\n",
    "        super().__init__(device=device_, dtype=dtype)\n",
    "        if R.dim() == 2:\n",
    "            R = R[None]\n",
    "        if R.shape[-2:] != (3, 3):\n",
    "            msg = \"R must have shape (3, 3) or (N, 3, 3); got %s\"\n",
    "            raise ValueError(msg % repr(R.shape))\n",
    "        R = R.to(device=device_, dtype=dtype)\n",
    "        if os.environ.get(\"PYTORCH3D_CHECK_ROTATION_MATRICES\", \"0\") == \"1\":\n",
    "            # Note: aten::all_close in the check is computationally slow, so we\n",
    "            # only run the check when PYTORCH3D_CHECK_ROTATION_MATRICES is on.\n",
    "            _check_valid_rotation_matrix(R, tol=orthogonal_tol)\n",
    "        N = R.shape[0]\n",
    "        mat = torch.eye(4, dtype=dtype, device=device_)\n",
    "        mat = mat.view(1, 4, 4).repeat(N, 1, 1)\n",
    "        mat[:, :3, :3] = R\n",
    "        self._matrix = mat\n",
    "\n",
    "    def _get_matrix_inverse(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Return the inverse of self._matrix.\n",
    "        \"\"\"\n",
    "        return self._matrix.permute(0, 2, 1).contiguous()\n",
    "\n",
    "\n",
    "class RotateAxisAngle(Rotate):\n",
    "    def __init__(\n",
    "        self,\n",
    "        angle,\n",
    "        axis: str = \"X\",\n",
    "        degrees: bool = True,\n",
    "        dtype: torch.dtype = torch.float32,\n",
    "        device: Optional[Device] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Create a new Transform3d representing 3D rotation about an axis\n",
    "        by an angle.\n",
    "\n",
    "        Assuming a right-hand coordinate system, positive rotation angles result\n",
    "        in a counter clockwise rotation.\n",
    "\n",
    "        Args:\n",
    "            angle:\n",
    "                - A torch tensor of shape (N,)\n",
    "                - A python scalar\n",
    "                - A torch scalar\n",
    "            axis:\n",
    "                string: one of [\"X\", \"Y\", \"Z\"] indicating the axis about which\n",
    "                to rotate.\n",
    "                NOTE: All batch elements are rotated about the same axis.\n",
    "        \"\"\"\n",
    "        axis = axis.upper()\n",
    "        if axis not in [\"X\", \"Y\", \"Z\"]:\n",
    "            msg = \"Expected axis to be one of ['X', 'Y', 'Z']; got %s\"\n",
    "            raise ValueError(msg % axis)\n",
    "        angle = _handle_angle_input(angle, dtype, device, \"RotateAxisAngle\")\n",
    "        angle = (angle / 180.0 * math.pi) if degrees else angle\n",
    "        # We assume the points on which this transformation will be applied\n",
    "        # are row vectors. The rotation matrix returned from _axis_angle_rotation\n",
    "        # is for transforming column vectors. Therefore we transpose this matrix.\n",
    "        # R will always be of shape (N, 3, 3)\n",
    "        R = _axis_angle_rotation(axis, angle).transpose(1, 2)\n",
    "        super().__init__(device=angle.device, R=R, dtype=dtype)\n",
    "\n",
    "\n",
    "def _handle_coord(c, dtype: torch.dtype, device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Helper function for _handle_input.\n",
    "\n",
    "    Args:\n",
    "        c: Python scalar, torch scalar, or 1D torch tensor\n",
    "\n",
    "    Returns:\n",
    "        c_vec: 1D torch tensor\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(c):\n",
    "        c = torch.tensor(c, dtype=dtype, device=device)\n",
    "    if c.dim() == 0:\n",
    "        c = c.view(1)\n",
    "    if c.device != device or c.dtype != dtype:\n",
    "        c = c.to(device=device, dtype=dtype)\n",
    "    return c\n",
    "\n",
    "\n",
    "def _handle_input(\n",
    "    x,\n",
    "    y,\n",
    "    z,\n",
    "    dtype: torch.dtype,\n",
    "    device: Optional[Device],\n",
    "    name: str,\n",
    "    allow_singleton: bool = False,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Helper function to handle parsing logic for building transforms. The output\n",
    "    is always a tensor of shape (N, 3), but there are several types of allowed\n",
    "    input.\n",
    "\n",
    "    Case I: Single Matrix\n",
    "        In this case x is a tensor of shape (N, 3), and y and z are None. Here just\n",
    "        return x.\n",
    "\n",
    "    Case II: Vectors and Scalars\n",
    "        In this case each of x, y, and z can be one of the following\n",
    "            - Python scalar\n",
    "            - Torch scalar\n",
    "            - Torch tensor of shape (N, 1) or (1, 1)\n",
    "        In this case x, y and z are broadcast to tensors of shape (N, 1)\n",
    "        and concatenated to a tensor of shape (N, 3)\n",
    "\n",
    "    Case III: Singleton (only if allow_singleton=True)\n",
    "        In this case y and z are None, and x can be one of the following:\n",
    "            - Python scalar\n",
    "            - Torch scalar\n",
    "            - Torch tensor of shape (N, 1) or (1, 1)\n",
    "        Here x will be duplicated 3 times, and we return a tensor of shape (N, 3)\n",
    "\n",
    "    Returns:\n",
    "        xyz: Tensor of shape (N, 3)\n",
    "    \"\"\"\n",
    "    device_ = get_device(x, device)\n",
    "    # If x is actually a tensor of shape (N, 3) then just return it\n",
    "    if torch.is_tensor(x) and x.dim() == 2:\n",
    "        if x.shape[1] != 3:\n",
    "            msg = \"Expected tensor of shape (N, 3); got %r (in %s)\"\n",
    "            raise ValueError(msg % (x.shape, name))\n",
    "        if y is not None or z is not None:\n",
    "            msg = \"Expected y and z to be None (in %s)\" % name\n",
    "            raise ValueError(msg)\n",
    "        return x.to(device=device_, dtype=dtype)\n",
    "\n",
    "    if allow_singleton and y is None and z is None:\n",
    "        y = x\n",
    "        z = x\n",
    "\n",
    "    # Convert all to 1D tensors\n",
    "    xyz = [_handle_coord(c, dtype, device_) for c in [x, y, z]]\n",
    "\n",
    "    # Broadcast and concatenate\n",
    "    sizes = [c.shape[0] for c in xyz]\n",
    "    N = max(sizes)\n",
    "    for c in xyz:\n",
    "        if c.shape[0] != 1 and c.shape[0] != N:\n",
    "            msg = \"Got non-broadcastable sizes %r (in %s)\" % (sizes, name)\n",
    "            raise ValueError(msg)\n",
    "    xyz = [c.expand(N) for c in xyz]\n",
    "    xyz = torch.stack(xyz, dim=1)\n",
    "    return xyz\n",
    "\n",
    "\n",
    "def _handle_angle_input(\n",
    "    x, dtype: torch.dtype, device: Optional[Device], name: str\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Helper function for building a rotation function using angles.\n",
    "    The output is always of shape (N,).\n",
    "\n",
    "    The input can be one of:\n",
    "        - Torch tensor of shape (N,)\n",
    "        - Python scalar\n",
    "        - Torch scalar\n",
    "    \"\"\"\n",
    "    device_ = get_device(x, device)\n",
    "    if torch.is_tensor(x) and x.dim() > 1:\n",
    "        msg = \"Expected tensor of shape (N,); got %r (in %s)\"\n",
    "        raise ValueError(msg % (x.shape, name))\n",
    "    else:\n",
    "        return _handle_coord(x, dtype, device_)\n",
    "\n",
    "\n",
    "def _broadcast_bmm(a, b) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Batch multiply two matrices and broadcast if necessary.\n",
    "\n",
    "    Args:\n",
    "        a: torch tensor of shape (P, K) or (M, P, K)\n",
    "        b: torch tensor of shape (N, K, K)\n",
    "\n",
    "    Returns:\n",
    "        a and b broadcast multiplied. The output batch dimension is max(N, M).\n",
    "\n",
    "    To broadcast transforms across a batch dimension if M != N then\n",
    "    expect that either M = 1 or N = 1. The tensor with batch dimension 1 is\n",
    "    expanded to have shape N or M.\n",
    "    \"\"\"\n",
    "    if a.dim() == 2:\n",
    "        a = a[None]\n",
    "    if len(a) != len(b):\n",
    "        if not ((len(a) == 1) or (len(b) == 1)):\n",
    "            msg = \"Expected batch dim for bmm to be equal or 1; got %r, %r\"\n",
    "            raise ValueError(msg % (a.shape, b.shape))\n",
    "        if len(a) == 1:\n",
    "            a = a.expand(len(b), -1, -1)\n",
    "        if len(b) == 1:\n",
    "            b = b.expand(len(a), -1, -1)\n",
    "    return a.bmm(b)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def _check_valid_rotation_matrix(R, tol: float = 1e-7) -> None:\n",
    "    \"\"\"\n",
    "    Determine if R is a valid rotation matrix by checking it satisfies the\n",
    "    following conditions:\n",
    "\n",
    "    ``RR^T = I and det(R) = 1``\n",
    "\n",
    "    Args:\n",
    "        R: an (N, 3, 3) matrix\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Emits a warning if R is an invalid rotation matrix.\n",
    "    \"\"\"\n",
    "    N = R.shape[0]\n",
    "    eye = torch.eye(3, dtype=R.dtype, device=R.device)\n",
    "    eye = eye.view(1, 3, 3).expand(N, -1, -1)\n",
    "    orthogonal = torch.allclose(R.bmm(R.transpose(1, 2)), eye, atol=tol)\n",
    "    det_R = _safe_det_3x3(R)\n",
    "    no_distortion = torch.allclose(det_R, torch.ones_like(det_R))\n",
    "    if not (orthogonal and no_distortion):\n",
    "        msg = \"R is not a valid rotation matrix\"\n",
    "        warnings.warn(msg)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735bc47e-8fbe-4e56-8b28-3a0aa36ac6c9",
   "metadata": {},
   "source": [
    "## Intrinsic matrix parsing\n",
    "\n",
    "From a calibrated camera's intrinsic matrix, calculate the following properties:\n",
    "\n",
    "- Focal length (in units length)\n",
    "- Principal point (in units length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f2cbe7-2edb-497e-ae26-2810ae383b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_focal_length(\n",
    "    intrinsic,  # Intrinsic matrix (3 x 3 tensor)\n",
    "    delx: float,  # X-direction spacing (in units length)\n",
    "    dely: float,  # Y-direction spacing (in units length)\n",
    ") -> float:  # Focal length (in units length)\n",
    "    fx = intrinsic[0, 0]\n",
    "    fy = intrinsic[1, 1]\n",
    "    return abs((fx * delx) + (fy * delx)).item() / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8cc2a3-7589-4c24-a75a-ec1a0f921750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_principal_point(\n",
    "    intrinsic,  # Intrinsic matrix (3 x 3 tensor)\n",
    "    height: int,  # Y-direction length\n",
    "    width: int,  # X-direction length\n",
    "    delx: float,  # X-direction spacing (in units length)\n",
    "    dely: float,  # Y-direction spacing (in units length)\n",
    "):\n",
    "    x0 = delx * (width / 2 - intrinsic[0, 2])\n",
    "    y0 = dely * (height / 2 - intrinsic[1, 2])\n",
    "    return x0.item(), y0.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26ca510-b8c3-4383-ad67-4ff9d852484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_intrinsic_matrix(\n",
    "    intrinsic,  # Intrinsic matrix (3 x 3 tensor)\n",
    "    height: int,  # Y-direction length\n",
    "    width: int,  # X-direction length\n",
    "    delx: float,  # X-direction spacing (in units length)\n",
    "    dely: float,  # Y-direction spacing (in units length)\n",
    "):\n",
    "    focal_length = get_focal_length(intrinsic, delx, dely)\n",
    "    x0, y0 = get_principal_point(intrinsic, height, width, delx, dely)\n",
    "    return focal_length, x0, y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe3b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a1ce35-7b44-4be5-981b-d436c2572a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
