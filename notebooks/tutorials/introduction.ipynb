{
 "cells": [
  {
   "cell_type": "raw",
   "id": "48cac364",
   "metadata": {},
   "source": [
    "---\n",
    "title: How to use `DiffDRR`\n",
    "description: In-depth tutorial of the `DRR` module's functionality\n",
    "output-file: introduction.html\n",
    "skip_exec: True\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from diffdrr.data import load_example_ct\n",
    "from diffdrr.drr import DRR\n",
    "from diffdrr.visualization import plot_drr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155c6c5d-5ca6-46f8-83fa-131b080f0fc8",
   "metadata": {},
   "source": [
    "## DRR Generation\n",
    "\n",
    "`DiffDRR` is implemented as a custom PyTorch module.\n",
    "\n",
    "All raytracing operations have been formulated in a vectorized function, enabling use of PyTorch's GPU support and autograd.\n",
    "This also means that DRR generation is available as a layer in deep learning frameworks."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3c9414f-edac-494a-a0fc-999dc4d86bc4",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "Rotations can be parameterized with numerous conventions (not just Euler angles).\n",
    "See [`diffdrr.DRR`](https://vivekg.dev/DiffDRR/api/drr.html#drr) for more details.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f421174-e98e-4de7-9cba-13884f517fe8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__take)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m rotations \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[torch\u001b[38;5;241m.\u001b[39mpi, \u001b[38;5;241m0.0\u001b[39m, torch\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]], device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     18\u001b[0m translations \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[bx, by, bz]], device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m---> 19\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mdrr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrotations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranslations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameterization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meuler_angles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvention\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mZYX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m plot_drr(img, ticks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/data/vision/polina/scratch/vivekg/miniforge3/envs/diffdrr/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/vision/polina/scratch/vivekg/miniforge3/envs/diffdrr/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data/vision/polina/scratch/vivekg/DiffDRR/diffdrr/drr.py:124\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, parameterization, convention, bone_attenuation_multiplier, *args)\u001b[0m\n\u001b[1;32m    122\u001b[0m     img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(img, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 124\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43msiddon_raycast\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdensity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspacing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreshape_transform(img, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(pose))\n",
      "File \u001b[0;32m/data/vision/polina/scratch/vivekg/DiffDRR/diffdrr/siddon.py:21\u001b[0m, in \u001b[0;36msiddon_raycast\u001b[0;34m(source, target, volume, spacing, eps)\u001b[0m\n\u001b[1;32m     19\u001b[0m alphas, maxidx \u001b[38;5;241m=\u001b[39m _get_alphas(source, target, spacing, dims, eps)\n\u001b[1;32m     20\u001b[0m alphamid \u001b[38;5;241m=\u001b[39m (alphas[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m alphas[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m:]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 21\u001b[0m voxels \u001b[38;5;241m=\u001b[39m \u001b[43m_get_voxel\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphamid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvolume\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspacing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxidx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Step length for alphas out of range will be nan\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# These nans cancel out voxels convereted to 0 index\u001b[39;00m\n\u001b[1;32m     25\u001b[0m step_length \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiff(alphas, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/data/vision/polina/scratch/vivekg/DiffDRR/diffdrr/siddon.py:85\u001b[0m, in \u001b[0;36m_get_voxel\u001b[0;34m(alpha, source, target, volume, spacing, dims, maxidx, eps)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_voxel\u001b[39m(alpha, source, target, volume, spacing, dims, maxidx, eps):\n\u001b[1;32m     84\u001b[0m     idxs \u001b[38;5;241m=\u001b[39m _get_index(alpha, source, target, spacing, dims, maxidx, eps)\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvolume\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midxs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__take)"
     ]
    }
   ],
   "source": [
    "#| cuda\n",
    "# Read in the volume and get the isocenter\n",
    "volume, spacing = load_example_ct()\n",
    "bx, by, bz = torch.tensor(volume.shape) * torch.tensor(spacing) / 2\n",
    "\n",
    "# Initialize the DRR module for generating synthetic X-rays\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "drr = DRR(\n",
    "    volume,      # The CT volume as a numpy array\n",
    "    spacing,     # Voxel dimensions of the CT\n",
    "    sdr=300.0,   # Source-to-detector radius (half of the source-to-detector distance)\n",
    "    height=200,  # Height of the DRR (if width is not seperately provided, the generated image is square)\n",
    "    delx=4.0,    # Pixel spacing (in mm)\n",
    ").to(device)\n",
    "\n",
    "# Set the camera pose with rotations (yaw, pitch, roll) and translations (x, y, z)\n",
    "rotations = torch.tensor([[torch.pi, 0.0, torch.pi / 2]], device=device)\n",
    "translations = torch.tensor([[bx, by, bz]], device=device)\n",
    "img = drr(rotations, translations, parameterization=\"euler_angles\", convention=\"ZYX\")\n",
    "plot_drr(img, ticks=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84f400d-4234-4613-ad03-f864a41ee672",
   "metadata": {},
   "source": [
    "We demonstrate the speed of `DiffDRR` by timing repeated DRR synthesis. Timing results are on a single NVIDIA RTX 2080 Ti GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c359856-8c25-416e-aca8-9586c0dfd4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| cuda\n",
    "%timeit drr(rotations, translations, parameterization=\"euler_angles\", convention=\"ZYX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da445df-67af-4893-bd4d-ae5a870c4982",
   "metadata": {},
   "source": [
    "### Fast rendering\n",
    "\n",
    "Since `diffdrr.DRR` is a `torch.nn.Module`, we can kernalize it with `torch.compile`. This improves the rendering time by roughly 2X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9faeb9-2bae-4c18-bbb1-9a13ae1a2f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch._dynamo.reset()\n",
    "c_drr = torch.compile(drr)\n",
    "_ = c_drr(rotations, translations, parameterization=\"euler_angles\", convention=\"ZYX\")\n",
    "_ = c_drr(rotations, translations, parameterization=\"euler_angles\", convention=\"ZYX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a793469-4320-4beb-86f1-c07fb2598a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 7 c_drr(rotations, translations, parameterization=\"euler_angles\", convention=\"ZYX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22108226-4b61-4327-bd3e-9cacf34ae569",
   "metadata": {},
   "source": [
    "### Sparse rendering\n",
    "\n",
    "You can also render random sparse subsets of the pixels in a DRR."
   ]
  },
  {
   "cell_type": "raw",
   "id": "296277be-6b59-4f77-b846-b1521d300221",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "Sparse DRR rendering can be useful in registration and reconstruction tasks when coupled with a pixel-wise loss, such as MSE.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd18626a-b8d3-4773-bbc7-c70c7f3ce8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| cuda\n",
    "# Make the DRR with 10% of the pixels\n",
    "drr = DRR(\n",
    "    volume,\n",
    "    spacing,\n",
    "    sdr=300.0,\n",
    "    height=200,\n",
    "    delx=4.0,\n",
    "    p_subsample=0.1,  # Set the proportion of pixels that should be rendered\n",
    "    reshape=True,  # Map rendered pixels back to their location in true space,\n",
    "    # Useful for plotting, but can be disabled if using MSE as a loss function\n",
    ").to(device)\n",
    "\n",
    "# Make the DRR\n",
    "img = drr(rotations, translations, parameterization=\"euler_angles\", convention=\"ZYX\")\n",
    "plot_drr(img, ticks=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2125ced8-1502-48e9-908f-7d6deb25b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit drr(rotations, translations, parameterization=\"euler_angles\", convention=\"ZYX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b26d79-0183-4025-83c9-2d41a8d39b2f",
   "metadata": {},
   "source": [
    "## Batched DRR synthesis\n",
    "\n",
    "The tensors for `rotations` are expected to be of the size `[batch_size, c]`, where `c` is the number of components needed to represent the rotation (`3, 4, 6, 10`).\n",
    "The tensors for `translations` are expected to be of the size `[batch_size, 3]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d1a40c-0106-4c9d-acf6-0e2051240a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drr = DRR(\n",
    "    volume,\n",
    "    spacing,\n",
    "    sdr=300.0,\n",
    "    height=200,\n",
    "    delx=4.0,\n",
    ").to(device)\n",
    "\n",
    "rotations = torch.tensor(\n",
    "    [[torch.pi, 0.0, torch.pi / 2], [torch.pi, 0.0, -torch.pi / 2]], device=device\n",
    ")\n",
    "translations = torch.tensor([[bx, by, bz], [bx, by, bz]], device=device)\n",
    "img = drr(rotations, translations, parameterization=\"euler_angles\", convention=\"ZYX\")\n",
    "plot_drr(img, ticks=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21862fb-faf6-4e7b-8ebd-1573cb137961",
   "metadata": {},
   "source": [
    "## Increasing DRR contrast\n",
    "\n",
    "CT scans are easily segmented using Hounsfield units. We can use this to identify which voxels are air, soft tissue, or bone. By up or downweighting voxels corresponding to bones, we can change the contrast of generated DRRs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5fd7d2-ec96-4185-a631-010fd89e8fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completely downweight bones in CT (i.e., only soft tissue)\n",
    "drr = DRR(\n",
    "    volume,\n",
    "    spacing,\n",
    "    sdr=300.0,\n",
    "    height=200,\n",
    "    delx=4.0,\n",
    ").to(device)\n",
    "\n",
    "rotations = torch.tensor([[torch.pi, 0.0, torch.pi / 2]], device=device)\n",
    "translations = torch.tensor([[bx, by, bz]], device=device)\n",
    "\n",
    "img = drr(\n",
    "    rotations,\n",
    "    translations,\n",
    "    parameterization=\"euler_angles\",\n",
    "    convention=\"ZYX\",\n",
    "    bone_attenuation_multiplier=0.0,\n",
    ")\n",
    "plot_drr(img, ticks=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4686d9f-6c92-4887-9677-2a8d297cfbd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
